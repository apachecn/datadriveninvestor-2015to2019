# 监控内容——社交媒体平台影响我们观点的好与坏

> 原文：<https://medium.datadriveninvestor.com/monitoring-content-the-good-and-bad-of-how-social-media-platforms-bias-structures-perspectives-a11223b989ce?source=collection_archive---------2----------------------->

[![](img/1eea0821203bf238913af1e89546fd3d.png)](http://www.track.datadriveninvestor.com/1B9E)

## 布兰登·派克:弗吉尼亚大学

社交媒体平台的核心是允许人们进行全球交流的论坛。从理论上讲，一个公正的论坛应该允许人们无拘无束地互相传递信息，并对相关内容进行公正的曝光。但这些平台已经找到了方法来证明添加某些言论规则的合理性。是否应该对发布的内容有任何限制，或者这些平台应该允许尽可能多的言论差异？

**理解社交媒体平台规则偏差的模型:**

在机器学习/统计中，有一个属性，即理解数据会受到误差的影响，误差以偏差、方差和“不可约误差”的形式存在( [1](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff) )。本质上，存在着基本的真理，为了理解这一点，我们通过我们容易出错的视角来看待它，

[](https://www.datadriveninvestor.com/2018/12/01/we-blocked-access-to-social-media-it-caused-an-outrage/) [## 我们屏蔽了社交媒体，这引起了公愤。-数据驱动型投资者

### 上瘾，我们看不出来。在最近的一项研究中，基于以前的研究成果，我们想…

www.datadriveninvestor.com](https://www.datadriveninvestor.com/2018/12/01/we-blocked-access-to-social-media-it-caused-an-outrage/) 

*   天生受制于“不可减少的错误”——这是无法消除的错误，是对现实持有某种有限观点的结果( [1](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff) )。
*   有偏见的视角—这是一个包含错误假设的视角，导致视角错过相关关系( [1](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff) )。
*   变化的视角—这是一种对数据微小波动的敏感性存在误差的视角( [1](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff) )。

偏见和差异相互对抗，一个坚定的、有偏见的观点变化较少，反之亦然。因此，当你减少一个来源的误差时，另一个来源的误差通常会增加。

> **偏差-方差困境**或**问题**是试图同时最小化这两个来源的[误差](https://en.wikipedia.org/wiki/Errors_and_residuals_in_statistics)([1](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff))的冲突。

![](img/bb17b39102b6207ca75767a3af6b9a63.png)

([2](https://djsaunde.wordpress.com/2017/07/17/the-bias-variance-tradeoff/)). As information capacity increases the variance in the data increases and we make erroneous judgements that everything we see is representative of the truth. In contrast, decreased information capacity causes to make erroneous judgements that are not well informed. There is some optimal middle that allows us to perceive as much of the truth as possible.

通过监控内容，社交媒体平台有能力改变用户看到的错误观点。平台要么会增加偏见，审查用户如何交流以及他们接触到什么，要么会通过让人们服从更多样化的群体和讨论来增加差异。这些平台的动机很难确定，是基于一些道德原则还是试图实现利润最大化。尽管如此，任何时候观点受到控制，理解它们如何改变我们对真相的认知是很重要的。

**好的和坏的**

让我们看看脸书的社区标准页面，看看它是如何试图控制内容的。请注意，所有社交媒体平台的这些政策都非常相似(并且具有代表性)。

> “我们认识到，让脸书成为一个人们感到有能力交流的地方是多么重要，我们认真对待我们在防止滥用服务方面的作用。这就是为什么我们制定了一套社区标准，概述了在脸书什么是允许的，什么是不允许的
> 
> 我们社区标准的目标是鼓励表达和创造一个安全的环境。我们的政策是基于我们的社区以及技术和公共安全等领域的专家的意见。“( [3](https://www.facebook.com/communitystandards/) )

脸书关注三个基本原则:安全、话语权和公平。它清楚地理解偏差方差权衡，因为安全和声音之间的紧张关系是暴露不同的视图和控制显示哪些视图以鼓励安全之间的紧张关系。让我们来看看内容暴露在哪里受到控制。虽然控制索赔保护我们免受情绪困扰，也许带走了我们一些重要的事实。在 The Verge 的一篇[文章中，讨论了脸书监控的一些内容，](https://www.theverge.com/2019/2/25/18229714/cognizant-facebook-content-moderator-interviews-trauma-working-conditions-arizona)

> “克洛伊将不得不在其他学员面前主持《脸书邮报》。当轮到她时，她走到房间的前面，那里的显示器显示一段视频，该视频已被发布到世界上最大的社交网络上。包括克洛伊在内，没有一个受训者见过它。她按播放键。
> 
> 这段视频描述了一名男子被谋杀的场景。有人捅了他几十刀，他尖叫着乞求饶命。克洛伊的工作是告诉房间这个帖子是否应该被删除。她知道《脸书社区标准》第 13 条禁止播放描述谋杀一人或多人的视频。当克洛伊向全班解释这一点时，她听到自己的声音在颤抖。
> 
> 回到她的座位上，克洛伊感到一种强烈的想哭的冲动。"( [4](https://www.theverge.com/2019/2/25/18229714/cognizant-facebook-content-moderator-interviews-trauma-working-conditions-arizona) )

显然，当人们在社交媒体平台上时，他们可能不想看到许多情绪刺激的内容。我当然不想去脸书看一场激烈的谋杀。脸书隐私条例中的“第 13 条”增加了一种约束和偏见，让我们呆在我们的社会泡沫中，不暴露于我们不想知道的暴行。我们愉快地欣赏“美味”的烹饪视频，阅读高中同学决定吹嘘的成功案例。

但是，通过对我们的内容进行监控和增加有偏见的观点，引入的错误可能比我们预期的更多。此外，在这篇文章中，我们发现接触所有被监控的内容如何改变了人们对历史和现实的关键看法，

> “员工们已经开始接受他们应该节制的视频和模因的边缘观点。凤凰城遗址是一个扁平地球人和一个大屠杀否认者的家。一名前雇员告诉我们，他不再认为 9/11 是一次恐怖袭击。( [4](https://www.theverge.com/2019/2/25/18229714/cognizant-facebook-content-moderator-interviews-trauma-working-conditions-arizona)

现在，地球是平的这一观点对于任何上过物理课的人来说似乎都很牵强(并且学过 F = Gm1m2/r)，所以极其多样的观点内容版主可能容易出错。也许在拍摄了数百个扁平地球的视频后，内容版主的观点变得有点缺陷。但也许如果我们看到这些平台上的所有信息，我们的观点会改变，以适应那些看起来更加多样和极端的观点。

最终，重要的是我们要理解偏差和变异的规则，以及它们如何在我们获取信息的过程中发挥作用。社交媒体施加高度偏见的例子很多，它们并不总是像删除恐怖内容那样无害。([观看蒂姆·普尔烤杰克·多西的律师关于 Twitter 本质上是政治左倾的，基于基本的 Twitter 政策](https://www.youtube.com/watch?v=_mP9OmOFxc4))。一旦我们理解了社交媒体平台强加的规则，我们就可以看到我们的观点是否被操纵在某个方向，并确保我们在现实中做出意见和决定。