# 人工智能中的伦理:三大挑战

> 原文：<https://medium.datadriveninvestor.com/ethics-in-ai-3-major-challenges-32cb4ac5d6f3?source=collection_archive---------8----------------------->

[![](img/e4f77e53a81aea7b80dd907eca2d8267.png)](http://www.track.datadriveninvestor.com/1B9E)![](img/1f7550b7caa53b261ab025d66df23c91.png)

正如我们所知，人工智能领域诞生于 20 世纪 50 年代，但随着传感器、数据和计算能力的爆炸，它在过去 5 年里真正起飞了。人工智能有能力帮助我们做出更快更好的决定，比如医生试图了解病人是否患有癌症。但是人工智能做得不完全或不正确也固有地带来放大我们世界中不可接受的行为的风险，比如说[谷歌的图像标签将黑人面孔归类为大猩猩](https://www.theverge.com/2018/1/12/16882408/google-racist-gorillas-photo-recognition-algorithm-ai)。人工智能中的偏见这一主题已经被广泛地撰写和讨论过——但我们并没有完全理解这一挑战，当然也没有所有的解决方案。这篇文章集中在三个主要问题上，可以说是按照我们管理它们的难易程度降序排列。

[](https://www.datadriveninvestor.com/2019/01/28/ai-creativity-deep-dream-comes-true/) [## 人工智能与创造力:梦想成真——数据驱动的投资者

### 人工智能总是让我着迷。不仅作为一套有用的工具，不断发展，而且作为一个…

www.datadriveninvestor.com](https://www.datadriveninvestor.com/2019/01/28/ai-creativity-deep-dream-comes-true/) 

**1)全面性**

通常情况下，你可能有太多的数据，而没有足够的数据。例如，如果我们只分析电子医疗记录(EMRs ),我们可能永远不会意识到疟疾每年影响多达 5 亿人——这种疾病是地方病，尤其是在没有充分使用 EMRs 的地区。更大的情况是，根据不够全面的数据训练的算法，很可能会继承导致失衡的偏见。

一个显而易见的解决方案是有目的地寻找更具体种类的数据。您还可以对不同类型的数据赋予不同的权重。另一种选择是模拟数据来填补空白。不管你最终使用哪种方法，这都需要知道有内在的缺陷。

**2)意识**

但是，当你甚至没有意识到你的数据集存在偏差时，该怎么办呢？也许你会发现没有意义的结果，从而进行更深入的探索。但是在很多情况下，你会发现问题太晚，或者不能完全诊断出来。当涉及深度学习方法时，这变得尤为关键，在这种情况下，人工智能更类似于一个黑盒，即很难解释它是如何得出特定结果的。

解释不可预见的事情说起来容易做起来难。除了增加数据的随机性和在现实世界中彻底测试算法，意识是一个特别困难的挑战。

**3)憎恶**

因为缺少一个更好的词，当机器反映出我们世界的丑陋时，就会发生憎恶。可能有大量的数据，算法可能已经建立并训练有素，但它可能最终反映出固有的缺陷。例如，如果人工智能要研究性别薪酬，它可能会内在化一种模式，即女性确实总是比男性挣得少——因为这是我们这个世界的不幸现实。如何给 AI 灌输与生俱来的是非感？谁来定义什么是对什么是错？我们如何随着时间进化出对错？这些都是我们没有很好答案的问题，企业家和风投有不回避辩论的内在义务。

这些是专注于实践见解的短文(我称之为 GL；dr —良好的长度；确实读过)。如果它们能让人们对某个话题产生足够的兴趣，从而进行更深入的探索，我会感到非常兴奋。这里表达的所有观点都是我自己的。如果这篇文章有对你有用的见解，请给个赞，任何想法请留言。