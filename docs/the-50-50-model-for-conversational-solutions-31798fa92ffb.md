# 对话式解决方案的 50-50 模型

> 原文：<https://medium.datadriveninvestor.com/the-50-50-model-for-conversational-solutions-31798fa92ffb?source=collection_archive---------5----------------------->

[![](img/5e02edb82d2a529f796576c9b994d7ca.png)](http://www.track.datadriveninvestor.com/1B9E)

对话解决方案或聊天机器人已经席卷了 IT 行业；大多数组织要么已经部署了一个或多个对话解决方案模型，要么正在进行第一次部署。每个聊天机器人都有两个主要组件——自然语言处理(NLP)和对话模型；两者协同工作，谁也不比谁更重要。让我们一个一个地看看这些组件

***NLP*** 或 ***自然语言处理*** 是聊天机器人的大脑。NLP 定义了聊天机器人将运行的域，聊天机器人能够理解多少变化，以及聊天机器人能够执行什么动作/交易。

***会话模型*** 是 NLP 层的支撑系统。对话模型定义了用户体验，并对聊天机器人的准确性起着主要作用；有了合适的对话模型，聊天机器人就可以驱动其领域内的用户。

确定了聊天机器人的组件后，让我们更深入地了解一个成功的聊天机器人的两个同等要素，这样我们就可以确定如何建立一个高效的模型。

***NLP 优化:***

1.  这个人工智能组件在机器学习模型或深度学习模型之上运行；无论使用哪种模型，都需要大量的数据和训练。
2.  "*我需要多少训练数据？*“这是每个 ML 开发者必须考虑的问题。这个问题的简单且相当不方便的答案是，“没有办法确定训练一个模型到底需要多少数据。”换句话说，对于每个场景，最佳数量的训练数据发生变化；对一种情况有效的方法对其他情况可能不会产生同样的结果。对于最初的聊天机器人训练，从每个意图 50 个训练短语开始，然后从那里开始。结合用户体验的回归测试将指示您是否需要将短语数量增加到每个意图 100 个，然后可能每个意图 500 个；为每个意图添加多达 1000 个短语可能最终是必要的，超过这个数量，回报就会递减。
3.  "*我如何构建训练短语模型？*“这里的关键是在每个意图中有相似数量的训练短语；最坏的情况是，短语计数的差异不应超过 30%，超过这个阈值将导致 ML 模型变得有偏差。
4.  "*如果培训导致 ML 模型变得有偏差，会发生什么？*“误报是聊天机器人开发过程中最常见的情况之一。如果你遇到假阳性，那么你的 ML 模型很有可能有偏差。要消除/减少误报，你需要重新审视训练中没有被发现的意图，并为意图添加更多的训练短语变体。
5.  "*什么时候我会使用参数化模型而不是非参数化模型？*“这是开发者很常见的问题或考虑。对于基于 FAQ 的聊天机器人，参数在响应推导中不起任何作用，拥有零参数模型通常会产生更好的结果。对于参数在响应推导和/或遵循哪个决策树中扮演重要角色的非 FAQ 机器人，则引入参数。
6.  "*什么是 ML 分类阈值，我如何实施它？*“阈值定义了机器人将匹配结果的置信度得分(即，低于阈值的置信度得分将导致机器人触发回退响应)。关于实际设置，有一个略高的阈值来去除/减少误报是非常重要的；最优选的值是 0.7 或 70%，但这并不意味着这将适用于所有场景。换句话说，需要一些反复试验来为你的机器人找到正确的阈值。

***对话式体验设计与开发:***

1.  *什么是对话模式？*“简单来说，NLP 是聊天机器人的大脑(或后端)，而对话模型是前端；它定义了用户如何与机器人交互。
2.  "*我如何才能最好地设计出合适的对话体验？*“聊天机器人的开发者首先要明白背后有人类的聊天窗口和聊天机器人的区别；前者是一个“开域”系统，后者是一个“闭域”。这种区别必须以一种帮助用户进入封闭领域的方式传达给聊天机器人的消费者，如果做得恰当，将会产生对用户有益的对话体验。
3.  "*如何为封闭领域设计良好的对话体验？*“为了获得最佳的用户体验，有必要通过告知用户聊天机器人的领域专业知识来有效地管理用户的期望。换句话说，在教育领域运行的聊天机器人必须告知用户它在该领域内可以覆盖的特定区域。
4.  "*有没有向用户告知领域专业知识的最佳实践？*“建议在推动整个谈话中起着重要作用；为了理解建议，建议您尝试一下谷歌助手的工作方式。谷歌的助手有一个非常简单的交互模型；它推动对话的方式简直太棒了，是在你的机器人中建立良好体验的最佳隐喻之一。
5.  "*你能为我总结一下谷歌建议模式吗？*“首先，你应该明白按照每个意图提供建议不会增加价值。在你的聊天机器人的欢迎响应和失败响应之后，应该有一个建议；在 welcome 中，机器人应该告知用户它可以帮助用户的基本类别(或者所有类别，如果只有少数类别的话)。失败之后，事情会变得有点棘手；您可能希望根据之前获得的意图提出建议，但当然，这并不总是可行的。
6.  "*你能给我举几个例子，说明基于先前意图的建议什么时候合适，什么时候不合适吗？比方说，一个用户向机器人提了一个问题(称之为 Q1 ),机器人正确地回答了。现在用户问机器人的第二个问题，(称之为 Q2)。如果 Q1 和 Q2 有关联，或者 Q2 是 Q1 的后续问题，那么来自 Q1 的建议将是有意义的。现在说问题 Q1 和 Q2 是完全不相关的；来自 Q1 的建议没有多大意义；在这种情况下，一套通用的建议会好得多。*
7.  "*在其他场景中，建议可能会有所帮助吗？*“绝对；在*完成*一项行动或交易后，你有机会添加一条有用的建议。在任何情况下，当机器人向用户请求一些信息时，你都不应该执行建议，因为这很可能导致混乱和偏离主题。
8.  "*我可以使用其他元素或设计技巧来改善我的聊天机器人的对话体验吗？*“再一次，绝对；“跟进”问题，也称为“上下文”问题，可以极大地改善用户体验。为了理解上下文问题或后续问题，思考正常的人与人的对话流程，以及如何在聊天机器人中实现这样的体验；换句话说，你的目标应该是与客户进行互动，就像他们直接与人交流一样。
9.  "*你能举一个基于上下文的跟进问题的例子吗？*“请考虑以下互动:

> o 用户要求:“如何更改地址？”o Bot 回应:“您可以通过填写此处的表格并在三十天内将其邮寄给我们来更改您的地址。”
> o 用户请求:“我把它邮寄到哪里？”
> o Bot 回应:“请将表格邮寄至<在此插入邮寄信息>

10."*关于后续问题，我还需要注意其他几点吗？*“思考这个概念最简单的方法就是记住，如果用户向机器人提出一些问题，那么他们很可能也会有一些后续问题。

最后，聊天机器人开发者必须明白，并不是每个来聊天机器人的人都是熟练的电脑用户。因此，聊天机器人提供的语言和指令必须能够让知识非常有限的人也能理解聊天机器人，并与之有效沟通。