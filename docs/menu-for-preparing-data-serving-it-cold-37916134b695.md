# 准备数据和冷盘的菜单

> 原文：<https://medium.datadriveninvestor.com/menu-for-preparing-data-serving-it-cold-37916134b695?source=collection_archive---------11----------------------->

[![](img/54036551dd00105b7688c4a8199398ac.png)](http://www.track.datadriveninvestor.com/1B9E)![](img/4ba34561d9d4cf2cb8769656b8fd24b2.png)

为了实现目标并满足对数据资产如何使组织受益的期望，需要首先确定如何成功执行数据分析工作流。作为一种良好的做法，数据科学家需要首先了解组织中项目的总体目标，以及每个成员或利益相关者希望从该数据集中实现什么。

一个好的开始方式是让所有感兴趣的相关方开始集思广益，集思广益，看看数据集能提供什么。集思广益会议之后，数据清理过程的手动部分开始，可以通过各种软件实现。一般来说，数据清理是从记录集、表或数据库中检测或删除损坏的和不准确的记录，并替换、修改或删除脏的、丢失的或粗糙的数据的过程。数据清理可以用数据辩论工具交互执行，也可以通过脚本进行批处理。

[](https://www.datadriveninvestor.com/2019/02/07/8-skills-you-need-to-become-a-data-scientist/) [## 成为数据科学家所需的 8 项技能——数据驱动型投资者

### 数字吓不倒你？没有什么比一张漂亮的 excel 表更令人满意的了？你会说几种语言…

www.datadriveninvestor.com](https://www.datadriveninvestor.com/2019/02/07/8-skills-you-need-to-become-a-data-scientist/) 

无论使用哪种软件，都需要对程序进行严密的记录、监控和不一致性审查，因此数据清理协议是必不可少的。这一点很重要，因为不正确或不一致的数据会导致错误的结论，并误导公共和私人领域的投资。例如，政府可能希望分析人口收入数字，以决定哪些地区需要在基础设施和服务方面进一步支出和投资。在这种情况下，获得可靠的数据以避免错误的财政决策是非常重要的。
下面的步骤 A 到 E 是用各种软件准备数据的想法，以便它在不同的平台上是可重复的，并且数据和结果是准确的。

**(A)** **安装**软件、依赖项和必要的库:软件可以包括安装新的包或加载现有的库，以便能够读取数据、转换或重塑数据、发现数据中的错误、分析和制表数据，并最终报告和传递数据。这包括能够读取数据、转换或重塑数据、发现数据中的错误以及最终分析和制表的软件。这可能包括使用 SQL、Python、SPSS、R、SAS 等。可以通过研究和投资数据清理工具(依赖项、库)来避免该步骤中的重复过程，从而可以批量分析数据，并且该过程是自动化的。

**【B】****导入**数据并读入所选软件:用户可能需要在所选软件之外将上游数据转换成现成的格式文件，以便读入所选软件。这里的步骤包括(I)暂存或定位文件，(ii)加载或导入数据，以及(iii)重新编码和转换数据格式以与其他软件兼容。还可以检查表格的前 5 行，以确保正确的输入。

**(C )** **清理**数据和监控错误:彻底检查数据集，了解字段。这包括查看数据趋势、异常值、最小值和最大值以及缺失数据或错误。下一步是记录大多数错误的位置，以便识别和修复不正确或损坏的数据类型，包括打字错误。如果要将数据与其他数据集集成，名称和变量的协调也是必要的。检查数据质量包括检查数据列和行的有效性、准确性、完整性、一致性和统一性。寻找异常值、平均值和误差幅度的例子。

**纠正**重复或错误的数据:与上面类似，作为质量保证的一部分，我们需要识别数据集中的重复和错误模式，因为这将有助于在分析时节省时间。该步骤还需要扫描数据链接的准确性和可再现性(如果已经执行)。这是通过在输入之前与文件进行交叉检查，并在确定性或概率性链接之前确保行数和列数与元数据匹配来实现的。这还可能包括测试单个列，例如，测试意外值，如空值、应为数字的非数字值、超出范围的值，以及数据链接差异。

**协调**并验证代码和数据的准确性:作为步骤 3-4 的重复，在清理数据后，通过扫描异常和矛盾来(重新)验证数据的准确性也很重要。例如，通过检查元数据信息来确定列名，转换日期或性别等。根据需要分析数据，通过检查元数据或转换日期或性别等来检测所有语法错误。根据元数据和解析数据来检测所有语法错误。这里的目的是避免冗长和重复的代码，编写更多的函数而不是循环，并减少或压缩源代码，使程序更加准确和可靠。注意:保持代码的简单和功能性是关键。这一步应该有助于代码和数据表的再现性，以便分析是可重复的和可信的。

**(D)分析**数据:在对数据进行标准化、验证和删除重复后，使用可靠的字段来分析数据，以进行高级描述性统计分析，如平均值、标准偏差、范围或聚类算法。这些结果可以用简单的频率表可视化为更复杂的图表。编译数据图，为商业智能和运营洞察分析提供更完整的信息。

**(E)与团队交流**结果:与团队交流新的标准化清洁流程和初步分析结果，并接受反馈，因为新鲜的视角和人们的洞察力几乎总是有利于改进分析。报告包括数据洞察和软件规范、用于分析数据的代码，以及被严密记录、导出并保存在相关文件夹中的结果，以便任何想要复制数据或从中产生新结果的人都可以访问这些结果。

在我从事的各种项目中，我已经无意识地经历了上述步骤的类似迭代，并认为制定一个逐步的菜单可能会有所帮助，所以我希望你喜欢。让我知道你的想法和缺失，感谢你的阅读。:)