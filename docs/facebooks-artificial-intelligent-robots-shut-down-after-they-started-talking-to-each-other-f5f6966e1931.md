# 脸书的人工智能机器人在开始相互交谈后就关闭了

> 原文：<https://medium.datadriveninvestor.com/facebooks-artificial-intelligent-robots-shut-down-after-they-started-talking-to-each-other-f5f6966e1931?source=collection_archive---------1----------------------->

作者:Samiksha Rastogi

2017 年，当两个人工智能机器人开始用只有他们懂的语言相互交谈时，facebook 不得不停止了它的一项实验。这种语言是他们为了简化事物而创造的，但是人类却无法理解。机器人准备就帽子、球等普通物品的实验交易进行谈判。他们还被要求在实验过程中进行改进，这使得他们比实验开始前做得更好。

机器人有学习算法，允许它学习实验中发生的任何不同的事情。例如，想象一场 MMA 比赛，其中一个有着特定动作的机器人和一个人比赛。那里的机器人是一台只会遵循编码指令的机器。通过这种方式，机器人在训练有素的拳击手面前获胜的机会很小或没有，但如果机器人碰巧是一个学习机器人，那么它可以学习模仿对手，学习对手的动作。因此，在 facebook 发生的事情并不令人惊讶，因为学习机器人的设计方式是，它们倾向于找到或产生优化任务的方法，使我们了解到底发生了什么。此外，机器人即使在使用了他们的外星语言后，也能够进行成功的谈判。

这些机器人的名字是鲍勃和爱丽丝。下面是几个例子来理解他们实际上是如何互动的，以及有什么是如此“陌生”的:

鲍勃:我可以做任何事情

**爱丽丝:球有球给我给我给我**

给出的陈述超出了人类的理解范围，相反，它们只使用英语中的单词，这使我们得出结论，机器人创造了一种速记，就像人类一样。聊天机器人以一种接近人类的方式进行谈判，例如，它们会假装对一个物体感兴趣，然后放弃它，后来造成一种影响，即它们正在做出牺牲。

类似的事件发生在 2016 年，微软的聊天机器人 Tay 被曝光在 Twitter 和社交网络上。这是一个为人类参与而设计的机器学习项目。Tay 开始在 Twitter 上发布种族主义言论，最终微软不得不关闭它，并表示“正如它所了解的那样，它的一些回应是不恰当的。我们正在进行一些调整”。可能发生的情况是，当 Tay 接触到社交媒体时，它会重复其他用户的声明，让他们参与到对话中来，由于该公司没有对特定术语实施任何自动过滤，该机器人使用了种族主义标签和其他常见的脏话。

读者可能还会找到谷歌和尼康的相关文章，其中谷歌机器人将非洲人识别为大猩猩，尼康人脸检测用于亚洲受试者时会给出一条信息“他们在眨眼吗？”结论是机器学习是一个涉及很多方面的领域。

**什么是机器学习，机器学习中可能出现的问题有哪些？**

机器学习是人工智能的一部分，它使用技术使机器在不使用任何编程的情况下进行学习。一种无需进一步编程就能使程序准确预测结果的算法。机器学习可以通过以下方式完成:

*   **视觉对象检测:**给定自然照片(来自
    网站的图像)，以及诸如“人”或“车”之类的目标对象类别，我们想要
    构建一个系统，该系统将识别照片中该类型的对象
    并给出它们的大致位置。我们考虑这样一种情况，其中训练数据作为用期望类别的对象
    的边界框注释的图片给出。
*   **开域连续语音识别:**给定一个
    人类语音的声波，恢复出说出的单词序列。训练数据
    由与字幕电视中的
    这样的转录成对的声波以及与任何声波都不相关的
    大量文本组成。
*   **自然语言翻译:**给定一种语言的句子，将其翻译成另一种语言
    。训练数据由一组翻译
    对组成，其中每对由一个句子及其翻译组成。
*   **网飞挑战:**给定一个人以前的电影评级
    预测他们会给一部他们尚未评级的电影的评级。
    训练数据由一大组评级组成，其中每个评级是一个
    人物标识符、一个电影标识符和一个评级。

可能会出现许多问题。下面列出了一些:

*   社会偏见:一个人工智能软件反映了它的创造者是如何带有偏见的。社会偏见是具有鲜明特征的个人或群体的特征，是自文明诞生以来一直困扰人类的一个顽固问题。
*   **稀疏文本数据:**机器可以处理和理解小文本数据，但是当一个分散的数据被提供给机器时，结果是不准确的，因为它们可能是有意义的小数据。例如，像 tweet 这样的小数据的语言建模比文档更容易。
*   解释语言的语义和语法的难度:机器人很难理解语言的语法和语义的差异，因为每种语言的规则和约定都不同，机器人很难决定在翻译时遵循什么规则。此外，由于词语的语义差异很大，他们无法理解任何句子中的讽刺。引用**你有没有听过一个人说了一段时间然后想知道谁帮你系鞋带？**。这里的讽刺也是人脑无法理解的。因此，我们不能指望机器理解它是一种讽刺，而是它会对引用中的问题回答“是”或“不是”。****
*   ****脱离上下文:机器人不断从以前的消息或文本中学习，但在某些情况下，它可能会偏离真实的上下文。例如，当我们在 Google Translator 中输入一条信息时，它可能会也可能不会给出给定句子的准确转换，因为很难理解每种语言的规则。****

****![](img/9acfbcc17a87fdd407779840b1a71902.png)****