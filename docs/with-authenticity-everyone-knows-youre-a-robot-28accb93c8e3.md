# 有了真实性，每个人都知道你是个机器人。

> 原文：<https://medium.datadriveninvestor.com/with-authenticity-everyone-knows-youre-a-robot-28accb93c8e3?source=collection_archive---------21----------------------->

[![](img/ae24cda1aaaff9082035535073d344c0.png)](http://www.track.datadriveninvestor.com/1B9E)![](img/8ab0de84b60347718c58cdd70e80fee9.png)

你听到这个消息了吗？OpenAI 是一家非营利性人工智能研究公司，[最近宣布，](https://blog.openai.com/better-language-models/)“我们已经训练了一个大规模无监督的语言模型，它可以生成连贯的文本段落，在许多语言建模基准上实现最先进的性能，并执行基本的阅读理解、机器翻译、问题回答和摘要——所有这些都没有特定任务的训练。”OpenAI 称这个模型为 GPT-2。

本质上，这句话的意思是，给定一个样本文本块，GPT-2 可以生成额外的文本，这些文本看起来来自相同的来源，对读者有意义。

在他们的博客文章中，OpenAI 确定了几个潜在的社会影响，预计 GPT-2 可用于创造:

*   人工智能写作助手
*   更有能力的对话代理
*   语言间的无监督翻译
*   更好的语音识别系统

同时也承认这种技术可能被滥用:

*   产生误导性的新闻文章
*   在线冒充他人
*   自动制作在社交媒体上发布的辱骂或伪造内容
*   自动化垃圾邮件/网络钓鱼内容的制作

可能还有其他他们还没有预料到的误用。

当然，世界上已经有很多误导性的新闻、身份假冒/盗窃和其他伪造的内容，但这些不端行为完全自动化的想法非常令人担忧。

由于担心滥用，OpenAI 只发布了 GPT-2 的精简版代码，其中不包括“数据集、训练代码或 GPT-2 模型权重”在这样做的同时，他们承认有一些研究人员有技术能力复制他们的结果。他们的最后建议是，“政府应该考虑扩大或开始采取措施，更系统地监控人工智能技术的社会影响和传播，并衡量此类系统能力的进步。”

幸运的是，真实性联盟中的企业已经开发了一种测量身份可靠性的程序。他们称之为“真实性”,它是基于韦斯·库斯毛尔(德尔斐，地球村)在他的书《安静的享受》、《逃离种植园》和《不要被绑架》中表达的观点

在他们的视频“[真实性元素](http://www.taivideos.com/VIDEO-Elements-of-Authenticity.html)”中，真实性联盟将真实性定义为当我们具备以下条件时存在的状态:

到处都有数字签名支持

可测量的可靠身份凭证

归用户所有，并提供

通过负责任的匿名保护隐私。

真实性联盟的另一个视频“记者证书”描述了联盟企业正在开展的工作，以打击假新闻和错误信息的传播，并追究那些传播误导或虚假故事的人的责任。

因为人工智能生成的故事不会包含数字签名，读者会被警告其不真实性。此外，如果任何有资格的记者在他们的报道中包含这种不真实的信息，他们可能要为传播错误信息负责。

为了更深入地了解真实的世界，我推荐在 WhatIsAuthenticity.com[的视频](https://whatisauthenticity.com/)

关于 OpenID 的 GPT-2 的更多信息，这里是我发现的一些东西:

【OpenAI.com】[《更好的语言模型及其启示》](https://blog.openai.com/better-language-models/)

[“这项技术可能会‘彻底摧毁’我们所知的互联网”](https://www.news.com.au/technology/innovation/design/this-technology-could-absolutely-devastate-the-internet-as-we-know-it/news-story/ee6578bd32e7bb979fea925380b63a37)(尼克·威格姆，News.com.au)

[“AI 可以写得跟我一样。《为机器人启示录做好准备》](https://www.theguardian.com/commentisfree/2019/feb/15/ai-write-robot-openai-gpt2-elon-musk#comments)(汉娜·简·帕金森，TheGuardian.com)

[“创造者称，新的人工智能虚假文本生成器发布可能太危险了”](https://www.theguardian.com/technology/2019/feb/14/elon-musk-backed-ai-writes-convincing-news-fiction)(亚历克斯·赫恩，TheGuardian.com)

[“一家由埃隆·马斯克支持的人工智能公司对一款文本生成工具保密，担心它太危险了”](https://www.businessinsider.com/openai-text-generating-tool-gpt2-wont-be-released-for-fear-of-misuse-2019-2)(伊索贝尔·阿舍·汉密尔顿，BusinessInsider.com)

[“open ai 构建了一个非常好的文本生成器，发布它被认为太危险了”](https://techcrunch.com/2019/02/17/openai-text-generator-dangerous/)(扎克·惠特克，TechCrunch.com)

[“制造假新闻的人工智能被认为太危险，不宜公开发布”](https://www.extremetech.com/extreme/285857-fake-news-generating-ai-deemed-too-dangerous-for-public-release)(瑞安·惠特瓦姆，ExtremeTech.com)