# NeurIPS2018 上的贝叶斯研究

> 原文：<https://medium.datadriveninvestor.com/bayesian-research-in-neurips2018-319cdbca71e9?source=collection_archive---------5----------------------->

![](img/92fc553d65f9ecc872657f8c8c81fe28.png)

欧洲信息处理系统会议被认为是人工智能领域最著名的学术会议。今年的会议， [NeurIPS2018](https://nips.cc/Conferences/2018) 于 12 月 3 日至 8 日在美丽的蒙特利尔举行。多亏了脸书，会议得以实时直播，所有讲座的视频都可以在 [NIPS 基金会脸书页面](https://www.facebook.com/nipsfoundation/)上看到。有一些非常有趣的主题演讲。我发现最吸引人的演讲是迈克尔·莱文教授的[神经系统外的生物电计算、原始认知和合成形态学](https://nips.cc/Conferences/2018/Schedule?showEvent=12487)。其他引人注目的主题演讲包括 Joelle Pineau 教授的[可重复、可重复使用和强大的强化学习](https://nips.cc/Conferences/2018/Schedule?showEvent=12486)，David Spiegelhalter 的[让算法值得信赖](https://nips.cc/Conferences/2018/Schedule?showEvent=12346)以及 Kunle Olukotun 的[为软件 2.0 设计计算机系统](https://nips.cc/Conferences/2018/Schedule?showEvent=12469)。还有一个关于[分子和材料的机器学习](https://nips.cc/Conferences/2018/Schedule?showEvent=10923)的非常有趣的研讨会，讨论在物理科学中的应用。

我关注 NeurIPS2018 主要是为了了解在**贝叶斯推理**中进行的最新研究及其在机器学习和人工智能中的应用。不出所料，在为期 6 天的会议中，有相当多的论文，超过 70 篇。大卫·邓森教授的关于[可扩展贝叶斯推理](https://nips.cc/Conferences/2018/Schedule?showEvent=10984)的第 0 天教程非常有用。本教程包含使用贝叶斯统计方法分析大规模数据集的最新方法的概述。邓森教授讨论了扩大常用的马尔可夫链蒙特卡罗(MCMC)算法的简单方法。讨论的一些例子是令人尴尬的并行(EP) MCMC、近似 MCMC、随机近似、混合优化&采样和模块化。这些方法在计算广告、基因组学和神经科学等领域都有应用。

还有两个与**贝叶斯推理**相关的工作坊。一个是关于[贝叶斯深度学习](https://nips.cc/Conferences/2018/Schedule?showEvent=10906)，另一个是关于[非参数贝叶斯推理](https://nips.cc/Conferences/2018/Schedule?showEvent=10905)，这两个都是目前非常活跃的研究领域。

口头报告和海报涵盖了**贝叶斯推理**的几个方面，包括理论进步和在机器学习中的应用。涵盖的主题包括贝叶斯深度学习，贝叶斯强化学习，贝叶斯优化，变分推理，变分自动编码器，马尔可夫链蒙特卡罗(MCMC)方法，表示学习或元学习，认知科学，差分隐私，近似贝叶斯方法和贝叶斯网络。这种广泛的主题显示了贝叶斯方法在机器学习和人工智能中的重要性。

我将在这里总结一些我觉得有趣的演讲/海报，完整的演讲/海报列表可以在 [NeurIPS2018 Proceedings](https://papers.nips.cc/book/advances-in-neural-information-processing-systems-31-2018) 页面上找到。

[**具有贝叶斯优化和最优传输的神经架构搜索**](https://nips.cc/Conferences/2018/Schedule?showEvent=12618)在这项工作中，作者开发了 NASBOT，一种用于神经架构搜索的基于高斯过程的贝叶斯优化框架。作者在神经网络结构的空间中开发了一种距离度量，它可以通过最优传输程序有效地计算。

[**通过贝叶斯网络结构学习构建深度神经网络**](https://nips.cc/Conferences/2018/Schedule?showEvent=11310)
本文介绍了一种深度神经网络无监督结构学习的原理方法。他们对深度和层间连通性提出了一种新的解释，其中输入分布中的条件独立性在网络结构中被分层编码，这使得网络的深度能够被固有地确定。该方法将神经网络结构学习问题转化为贝叶斯网络结构学习问题。

[**解释深度学习模型——贝叶斯非参数方法**](https://nips.cc/Conferences/2018/Schedule?showEvent=11445)在这项工作中，作者提出了一种新的技术方法，用多个弹性网来增强贝叶斯非参数回归混合模型。使用增强的混合模型，人们可以通过全局近似提取目标模型的可概括的洞察力。

[**贝叶斯对抗性学习**](https://nips.cc/Conferences/2018/Schedule?showEvent=11664)深度神经网络容易受到对抗性攻击，标准的防御方法是将其公式化为鲁棒优化问题。这里，我们最小化从*对手数据生成分布*中得出的最坏情况损失的点估计。在这项工作中，提出了一种新的稳健训练框架，称为*贝叶斯稳健学习*，其中，在对抗性数据生成分布上放置一种分布，以说明对抗性数据生成过程的不确定性。

[**贝叶斯分布式随机梯度下降**](https://nips.cc/Conferences/2018/Schedule?showEvent=11617)该工作讨论了一种在并行集群上训练深度神经网络的高通量算法。该算法在深度生成模型中使用摊销推理，以计算集群特定的方式执行小批量梯度计算时间的联合后验预测推理。特别地，该算法通过选择最佳截止值来减轻同步的、基于梯度的优化中的掉队效应，超过该最佳截止值，来自慢工人的小批量梯度消息被忽略。

[**贝叶斯模型不可知元学习**](https://nips.cc/Conferences/2018/Schedule?showEvent=12594)本文提出了一种新的贝叶斯模型不可知元学习方法，用于从小数据集学习。所提出的方法在一个原则概率框架内结合了有效的基于梯度的元学习和非参数变分推理。

[**【美在平均中】及其语境调节:贝叶斯统计解释**](https://nips.cc/Conferences/2018/Schedule?showEvent=11405)理解人类如何感知高维物体(如人脸)的可爱程度是认知科学和人工智能/人工智能中的一个重要问题。众所周知，从心理学文献来看，人类对面部吸引力的评估是依赖于环境的。在这篇论文中，作者假设，当一个对象导致较低的编码成本时，特别是当其感知的*统计典型性*较高时，人类对该对象的偏好会增加，这与巴洛开创性的高效编码假设相一致。

[](https://nips.cc/Conferences/2018/Schedule?showEvent=11379)**根据演示对时态任务规范的贝叶斯推断当观察任务演示时，人类学徒能够在他们获得实际执行该任务的专业知识之前很久就识别出给定任务是否被正确执行。作者提出了*贝叶斯规格说明推理*，这是一个概率模型，用于将任务规格说明推断为时态逻辑公式。作者结合了概率规划的方法来定义他们的先验，以及独立于领域的似然函数来实现基于采样的推理。**

**[**鞍点预测近似贝叶斯计算**](https://nips.cc/Conferences/2018/Schedule?showEvent=11971)近似贝叶斯计算(ABC)是在似然函数难以处理的情况下进行贝叶斯推理的重要方法。在本文中，作者介绍了一个基于优化的 ABC 框架，解决现有方法中的不足。利用后验和联合分布匹配的生成模型，作者表明 ABC 可以被构造为鞍点问题，其目标可以通过样本直接访问。**

**[**多专家强化学习:贝叶斯模型组合方法**](https://nips.cc/Conferences/2018/Schedule?showEvent=11906)在本文中，作者应用贝叶斯模型与多专家的组合，其方式是随着训练的进行，学习信任专家的良好组合。**

**[**变分贝叶斯蒙特卡罗**](https://nips.cc/Conferences/2018/Schedule?showEvent=11786)科学计算和机器学习中感兴趣的许多概率模型是难以处理的，需要访问梯度或大量的似然性评估。作者在这里介绍了一个新的样本有效的推理框架，*变分贝叶斯蒙特卡罗* (VBMC)。VBMC 将变分推理与基于高斯过程的主动采样贝叶斯求积相结合，使用后者来有效地逼近变分目标中的棘手积分。**

**[**使用随机梯度的深度高斯过程中的推理哈密尔顿蒙特卡罗**](https://nips.cc/Conferences/2018/Schedule?showEvent=11722)深度高斯过程(DGPs)是高斯过程的分级概括，其将良好校准的不确定性估计与多层模型的高度灵活性相结合。这些模型面临的最大挑战之一是，精确的推断是难以处理的。在这项工作中，作者为后验分布的非高斯性质提供了证据，并应用随机梯度哈密顿蒙特卡罗方法从后验分布生成样本。**

**[**算法保证:使用贝叶斯优化的算法测试的主动方法**](https://nips.cc/Conferences/2018/Schedule?showEvent=11534)在这项工作中，作者介绍了算法保证，即测试机器学习算法是否符合其预期设计目标的问题。作者从数学上把这项任务表述为一个昂贵的黑盒函数的优化问题。他们使用基于贝叶斯优化的主动学习方法来解决这个优化问题。**

**[**离散松弛连续变量用于易处理的变分推理**](https://nips.cc/Conferences/2018/Schedule?showEvent=12713)作者探索了具有离散隐变量先验的贝叶斯变分推理的一个新的研究方向，他们利用 Kronecker 矩阵代数进行证据下界(ELBO)的高效精确计算。这导致后验样本由稀疏且低精度的量化整数组成，这允许在硬件有限的设备上进行快速推断。**

**[**Wasserstein 变分推理**](https://nips.cc/Conferences/2018/Schedule?showEvent=11256)本文介绍了 *Wasserstein 变分推理*，一种基于最优运输理论的近似贝叶斯推理的新形式。Wasserstein 变分推理使用了一个新的散度族，包括 f-散度和 Wasserstein 距离作为特例。这种技术产生了一种非常稳定的无似然训练方法，可以用于隐式分布和概率程序。**

**[**在变分自动编码器中学习潜在子空间**](https://nips.cc/Conferences/2018/Schedule?showEvent=11623)通常很难解释使用*变分自动编码器* (VAE)学习的潜在空间表示。作者提出了一个基于 VAE 的生成模型，该模型能够提取数据中与二进制标签相关的特征，并将其构造在一个易于解释的潜在子空间中。**

**[**用于分子设计的约束图变分自动编码器**](https://nips.cc/Conferences/2018/Schedule?showEvent=11748)通过强调在化学中的应用，作者探索了学习生成符合在训练数据中观察到的分布的图的任务。他们提出了一种变分的自动编码器模型，其中编码器和解码器都是图结构的。他们表明，通过使用潜在空间的适当成形，该模型允许设计在期望特性方面(局部)最优的分子。**

**我可能在这里省略了 NeurIPS2018 上展示的关于**贝叶斯推理**的其他几项重要工作。这部分是因为我个人的选择，也可能是我在会议上提交的数百篇论文和海报中没有注意到它们。我鼓励读者通过搜索《2018 年神经病学会议录》来寻找其他有趣的论文。**

**总之，NeurIPS2018 上展示的关于贝叶斯推理的广泛工作列表显示了该主题在现代机器学习和人工智能时代的相关性。在更好的后验密度估计算法以及从深度学习模型解释到新分子设计等问题的应用方面，最新的贝叶斯推理去年取得了一些重要进展。**