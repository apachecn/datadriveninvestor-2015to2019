# 随机森林算法

> 原文：<https://medium.datadriveninvestor.com/random-forest-algorithm-777e6597bfcc?source=collection_archive---------7----------------------->

[![](img/28a5fc4aa9c1533887d5a77b55093dd2.png)](http://www.track.datadriveninvestor.com/1B9E)

很容易使用机器学习算法，甚至可以在没有超参数调整的情况下工作。它可用于分类和回归任务。这是一个监督学习算法，创建森林，并使其随机。森林是用 Bagging 方法训练的决策树的集合。

它构建多个决策树，并将它们合并在一起，以获得更准确的结果。它具有与决策树或 bagging 分类器几乎相同的超参数。

![](img/a37fa8e3e712254f8555b9028a6c59a9.png)

Source : [SlidePlayer](http://www.slideplayer.com)

随机森林在形成决策树时增加了模型的随机性。它不是搜索最重要的特征，而是从随机的特征子集中搜索最佳特征。它导致多样化，使我们的模型更好。我们可以通过为每个特征使用一些阈值而不是搜索最佳阈值来使我们的模型更加随机。

在进行预测时，测量特征的相对重要性是非常容易的。

## 超参数

*   ***预测能力:*****【n _ estimators】**是在构建算法并采取多数投票或取平均值之前定义树的数量的参数。更多的树可以提高模型的性能，但同时也会降低模型的速度。另一个参数是 **"max_features"** ，它定义了算法所涉及的最大特征数。最后一个可以修改预测能力的参数是 **"min_sample_leaf"** ，它只是告诉我们分裂内部节点所需的最少叶子数。
*   ***型号速度:*****【n _ jobs】**参数告诉引擎它可以使用多少个处理器。如果它的值= 1，它可以使用 1 个处理器，如果它的值= -1，则没有限制。**“随机状态”**使输出可复制。如果它有一个确定的 random_state 值，它总是产生相似的结果。**“OOB _ score”**(OOB 采样)是检查模型速度的另一个参数。它不使用三分之一的数据进行训练，而是在以后用于模型的评估。这些样品是袋外样品。

我们将在后面的帖子中讨论随机森林的实现。 ***快乐编码！！！***