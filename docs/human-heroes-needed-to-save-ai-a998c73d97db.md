# 拯救人工智能需要人类英雄

> 原文：<https://medium.datadriveninvestor.com/human-heroes-needed-to-save-ai-a998c73d97db?source=collection_archive---------15----------------------->

好吧，这是一个大胆的说法，也是一个很难验证的说法，但这是我今天在 [RSA](https://www.thersa.org/events/2018/09/how-to-be-human-in-the-age-of-the-machine) 听[汉娜·弗莱的](https://en.wikipedia.org/wiki/Hannah_Fry) [@FryRsquared](https://twitter.com/FryRsquared) 精彩演讲时脑海中持续不断的声音。

人工智能的失败是有据可查的，从一些算法设计的短视，或者对许多人来说以极其危险的方式出现的无意识偏见，或者只是粗心的编码和错误。所有这些无疑都很重要，但在其他地方已经详细讨论过了。弗莱女士的话让我印象深刻的是，我们根深蒂固、看似矛盾的冲动，既毫无疑问地依赖技术，又因为技术不完美而非理性地拒绝它，这就是风险。这些是(非常)人性的弱点。

演讲中使用的例子(以及她的书 [Hello World](https://www.penguin.co.uk/books/1114076/hello-world/) )范围广泛，从即使常识显示我们走错了路，人们对卫星导航系统的普遍信任，到常识更严重的失败，即根据错误的算法逻辑评估重新犯罪的可能性，对罪犯的判决进行过度控制(见 Fry 书中的 Brooks vs State of Virginia)。

与目前流行的反乌托邦人工智能观点不同，Fry 的工作着眼于我们如何与人工智能合作以创造更美好的未来，以及我们需要做些什么来实现它。在我看来，她的演讲提出了三个需要解决的连锁问题，以确保我们对人工智能负责。

我们(人类)应该如何管理 AI？

我们应该如何决定(作为企业、社会和个人)边界应该建立在哪里？

最后，我们需要如何改变我们的行为来充分利用人工智能世界？

许多比我更聪明的人无疑会在未来几年讨论这些问题，但我确实认为有一条共同的线索必须构成答案的基础。

我们需要找到更好的语言和更好的故事来帮助人们理解这些技术在他们的生活中做了什么以及为什么。

正如一些观众所说，人工智能的问题是它听起来太可怕了。[人工](https://www.thefreedictionary.com/artificial)的意思是‘不自然’，模仿，虚假，不真诚，似乎寻求欺骗。智慧本身是冷酷无情的。合在一起，他们想象出一个冷酷无情的未来也就不足为奇了——即使没有提到终结者！

但是，像今天的观众建议的智能辅助(IA)或决策支持系统(自 20 世纪 70 年代以来)这样的替代方案几乎一样糟糕，不太可能流行起来。仅仅提到“人工智能”就能让公司估值增加 10%,这似乎让人难以释怀。

但是，我们是否可以通过提供更好的背景和更具包容性的故事来帮助人们理解正在发生的事情以及这些事情如何帮助他们，从而缓和这种说法呢？技术专家有一个坏习惯，那就是创造他们自己的语言，这种语言对外界来说既复杂又神秘。是的，毫无疑问，它们需要传达复杂的东西，但正如 Fry 今天展示的那样——只要稍加思考和努力，即使复杂的过程也可以用通俗易懂的方式来解释。

要回答上述问题，我们需要社会各界进行更具包容性、冷静和知情的辩论，以确保答案有效、合理并为大多数人所接受。

为了进行这场辩论，人工智能行业(以各种形式)需要开始用大众理解的语言创造补充、证明和例子。这意味着从以产品(或甚至商业)为中心的传播转向解决受这些产品影响的人群的背景、价值和关注的故事。

不离开技术掩体的危险在于，人工智能创新者将发现这场辩论越来越有害，监管机构的关注也越来越繁重。人工智能在许多方面改善我们的生活、社会和经济方面发挥着重要作用。但是，如果不以令人信服和相关的方式阐明这种好处，这就不可能发生。

让我们以人类为英雄重新讲述人工智能的故事。

�