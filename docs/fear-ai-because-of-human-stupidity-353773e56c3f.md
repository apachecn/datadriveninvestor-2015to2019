# 因为人类的愚蠢而恐惧 AI

> 原文：<https://medium.datadriveninvestor.com/fear-ai-because-of-human-stupidity-353773e56c3f?source=collection_archive---------9----------------------->

![](img/da78bbe2c198fe08b6e6ee669edc6bfd.png)

Image by [Gerd Altmann](https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3382507) from [Pixabay](https://pixabay.com/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3382507)

我刚刚看完[丹尼尔·雅莫鲁克](https://medium.com/@daniel.yarmoluk)的文章[不要害怕人工智能，害怕人类的愚蠢](https://medium.com/hackernoon/dont-fear-ai-fear-human-stupidity-437fd22e1a93)。这篇文章的核心观点之一是，我们需要专注于提高人类的理性。我完全同意:人类正面临着许多问题，如果我们以正确的方式思考它们，并采取适当的行动来解决它们，这些问题是可以解决的。然而，同一篇文章中提到的另一点如下:人工智能可能在(不久的)未来毁灭人类的警告大多“经不起更仔细的审查”。这个想法是，我们不应该害怕人工智能(AI)，我们应该害怕人类的愚蠢。我引用:

> “为什么人工智能机器人想要灭绝人类——特别是如果它们是智能的话？这种担心本身是理性的吗？”

[](https://www.datadriveninvestor.com/2019/03/01/the-myth-of-ais-predictive-power/) [## 人工智能预测能力的神话|数据驱动的投资者

### AI(人工智能)最有前途的优势之一似乎是它预测未来的能力…

www.datadriveninvestor.com](https://www.datadriveninvestor.com/2019/03/01/the-myth-of-ais-predictive-power/) 

是的丹尼尔。这种担心是非常理性的。但是，正如你似乎暗示的那样，人们担心的主要不是人工智能机器人，它们想以灭绝人类为目标。这种担忧甚至不一定与机器人有关。人们担心的是人工智能，为了实现它的目标，它作为一个*副作用*灭绝了人类，因为它根本不关心我们。足够聪明的人工智能将(可能)意识到更多的智能将帮助它实现目标，因为智能可以(部分)定义为一个人实现目标的能力。为了不断增加自身的智能，它将需要更多的计算能力；为了达到这个目的，为什么不最终将整个星球改造成一台巨型超级计算机呢？

> 人类因为人工智能而灭绝只是一个副作用。

当然，这将取决于人工智能的目标:如果目标是让人类活着，它不能改造整个地球(包括人类)，因为那会杀死我们。然而，对于许多目标来说，将地球改造成一台超级计算机会有所帮助。人类因此而灭绝只是一个副作用。人工智能会怎么做？它可能会教导并说服人类建立纳米技术工厂，生产能够将普通物质转化为计算物质的(纳米)机器人。足够智能的人工智能可以令人信服地说服人类做它希望人类做的事情(例如参见[人工智能盒子](https://en.wikipedia.org/wiki/AI_box)实验)。

> 对于我们来说，建立一个友好的人工智能，我们必须弄清楚如何建立一个 AGI 加上如何使它友好。

现在，我再次同意丹尼尔关注人类理性的观点。我认为，创造一种所谓的友好人工智能是可能的:一种人工通用智能(AGI:一种在所有认知领域都与人类大致一样聪明的人工智能)，对人类产生积极而非消极的影响。然而，这必然比构建一个不一定友好的人工智能更困难。对于我们来说，建立一个友好的人工智能，我们必须弄清楚如何建立一个 AGI *加*如何使它友好。对于这一点，我们确实必须非常理性地思考。我的建议是:害怕 AI *因为*人类的愚蠢，因为人类在建设 AGI 时的愚蠢会导致一个没有友好的 AGI。