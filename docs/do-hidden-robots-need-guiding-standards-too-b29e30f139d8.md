# 隐藏机器人也需要指导标准吗？

> 原文：<https://medium.datadriveninvestor.com/do-hidden-robots-need-guiding-standards-too-b29e30f139d8?source=collection_archive---------43----------------------->

[![](img/e65db49f3fad9ff3881ec3863861cd37.png)](http://www.track.datadriveninvestor.com/1B9E)![](img/a1b220d1100ca79614fad3eb3dfee5df.png)

甚至早在 1942 年，就有人梦想人工智能的时代会是什么样子。像艾萨克·阿西莫夫这样的未来学家正在考虑新的自主技术的风险。就在那一年，阿西莫夫写了一篇名为《逃避》的短篇小说，其中他揭示了机器人三定律。

这些法律的关键主题是，机器人不能通过行动或不行动让伤害降临到人类身上。多年来，哲学家和作家都以无数种方式研究了这些法律，揭示了语言中的漏洞以及在边缘案件中可能出现的挑战。不管怎样，如果机器人走进我们中间，这些原则似乎是我们想要的东西。它们应该有助于改善我们的生活。

如果你看过[波士顿动力公司的机器人](https://www.bostondynamics.com/)的视频，你就会明白为什么需要三大定律，至少在情感层面上是如此。波士顿动力公司制造了各种类似动物/人的机器，它们看起来像是科幻电影中的东西，在这部电影中，机器人不是仁慈的仆人，而是决心成为我们的主人。这些机器人的视频是支持在[阿特拉斯走到我们中间](https://www.bostondynamics.com/atlas)之前制定这些法律的证据。

但是那些隐藏的机器人呢？这些机器人只是作为隐藏在云托管设施的网络服务器上的代码行而存在，看起来并不危险。我们是否也应该考虑这些引擎的设计指导原则，这些引擎提供我们的数据，并据称应该使我们的用户体验更好？

这似乎是显而易见的。然而，任何人都可以注册自己的基于云的托管账户，其中可能包括一个机器学习初学者工具包。通过一点技巧和正确的数据，一个熟练的数据科学家可以创造出一种技术，这种技术可以做二十年前看起来不可思议的事情。在更有才华的经营者手中，存在着更多非凡的可能性。那么，在这些开发者向我们释放他们的机器之前，他们对社会有什么责任呢？

我怀疑欧盟将在这一领域发挥领导作用，就像他们在隐私领域所做的那样。我还怀疑机器人/人工智能的初始法律对我来说更侧重于披露，而不是遵守行为规范。但这是那种可能失控的事情，不是以天网的方式，而是以 T2·脸书与隐私斗争的方式。这项技术将比我们对它以及创造它的人类将如何使用它的理解领先两步。

我对人工智能拥有近乎神奇的能力来改善我们生活的许多方面的可能性持乐观态度。但就像隐私一样，我认为我们必须预见到这种技术可能产生负面影响的风险。我们需要有意识地确保机器学会为我们的利益而工作。

*原载于 2019 年 1 月 9 日*[*solosegment.com*](https://solosegment.com/blog/do-hidden-robots-need-guiding-standards-too/)*。*