# 让人们意识到歧视性机器学习算法

> 原文：<https://medium.datadriveninvestor.com/bringing-awareness-to-discriminatory-machine-learning-algorithms-e0a66341ae69?source=collection_archive---------2----------------------->

![](img/d02628571b1f9fd1960c736e20c6883e.png)

# 概观

机器学习正在慢慢被整合为几乎每个行业的主要工具。这带来了许多好处，如增加收入和更好的决策，但数据科学家和组织必须意识到关于机器学习的道德规范。这是因为机器学习本质上并不公平或公正。这取决于数据科学家在道德上以一种不会有害地歧视人群的方式利用这些工具。一个显而易见的领域是预测监管算法。机器学习算法通过基于历史数据制定规则来“学习”，并可用于发现联系、相关性和预测未来结果。因此，数据科学家必须认识到用于训练算法的训练数据中固有的任何潜在的社会偏见。这个问题也与少数民族的数据相对较少有关。因此，关于少数民族的算法通常不如关于一般人群的算法准确。这意味着我们可以有一个整体上看起来准确的算法，但对少数群体来说不准确。

讨论这些问题并让人们意识到一个极其重要但经常被忽视的问题是很重要的。同样值得一提的是成为一名高效且有道德的数据科学家所必需的“软技能”和领域知识。重要的是要优先考虑公平性，并相应地利用资源。如果机器学习只对美国白人有效，那它有什么用？不幸的是，种族主义和性别歧视在美国仍然是一个紧迫的问题，因此，当代数据科学家有责任了解社会状况，并在反对歧视的斗争中尽自己的一份力量。

![](img/cf1d75077c09bc6101b82e10819c6e99.png)

# 监管机构和政治

我完全同意计算机算法可能是歧视性的，并强化人类的偏见。我认为缓解这些问题的关键是在我们的组织内培育一个集成的数据生态系统。需要有适当的制衡，让人们可以自由地就这些问题进行公开对话。通常，确保一个特定的算法尽可能的公平和公正可能会更加耗时和昂贵。因此，至关重要的是，我们组织的领导重视道德数据的做法高于一切。利益相关者可能很容易忽视这些问题，尤其是如果它们没有显著影响收入，这就是为什么这些问题必须非常认真地对待。

我们已经认识到重视私营部门道德数据实践的重要性，但是监管机构和公共政策在降低这种风险方面的作用是什么？我认为奥巴马政府在公共政策中优先考虑数据科学方面迈出了一大步。理想情况下，这种对数据的关注将渗透到我们的地区、州和地方政府及监管机构。他们必须在减轻歧视性计算机算法对美国公众的风险方面发挥积极作用。数据不流畅似乎是这些问题经常被忽视的部分原因。

“懂”数据科学、机器学习、人工智能的人不多；而那些知道的人有时并不关心或者没有资源来有效地评估他们潜在的歧视性算法。这就是为什么自上而下的数据流畅性和道德数据实践方法似乎是合理的选择。我们的政治领导人和私营部门领导人都需要对数据科学和与之相关的伦理问题有一个基本的认识。

[![](img/4270b3e4285d19c2c93be3eb63673c5e.png)](http://eepurl.com/dw5NFP)