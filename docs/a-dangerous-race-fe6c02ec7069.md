# 危险的比赛

> 原文：<https://medium.datadriveninvestor.com/a-dangerous-race-fe6c02ec7069?source=collection_archive---------23----------------------->

![](img/50db8d6b96b2bd9fe7444ee1a57694e1.png)

“programming language codes” by [Markus Spiske](https://unsplash.com/@markusspiske?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

在同一个对话中，很少听到人工智能说出的词没有听到风险这个词。然而，无论人们认为这些担忧是否合理，都很难反驳以下观点:如果开发或执行不力，人工智能将对我们的社会构成实质性威胁。事实上，即使是人工智能的坚定支持者，在谈到人工智能的危险如何被夸大时，也会总结说*如果做得正确*，我们没有什么可担心的。但是，认为每个公司和国家都会投入必要的资源来安全地开发人工智能，即使不是完全天真，也似乎是冒昧的。这篇短文并不试图确定人工智能可能带来什么风险，或者我们如何避免这种危险。许多比作者更有成就的研究人员已经开始了这项工作；相反，这篇文章旨在说服读者，当考虑当前的激励结构时，许多参与者很可能会忽视人工智能的安全。这意味着，通过断言如果操作正确，就不会有任何危险来压制对人工智能危险的担忧是愚蠢的。这种说法并没有解决潜在的担忧，即人工智能开发工作不太可能正确完成。

我们正在进行一场人工智能竞赛，获胜者将获得丰厚的奖励。对企业来说，获得先发优势可以让它们建立起知识产权的护城河，让更多的企业难以进入这个市场。对基础知识产权的控制可以建立一个统治世界的庞然大物，就像美国电信公司高通一样，它在历史上统治着智能手机芯片市场。然而，更进一步来说，赢得第一名可以让获胜者制定游戏规则。高通在建立 3G 和 LTE 无线通信标准方面发挥了关键作用。回报不仅限于商业。一个国家可以从本土人工智能技术巨头那里获得很多好处，尤其是经济优势。有如此多的利害关系，人工智能竞赛不可避免应该是不言而喻的。

有些人会声称竞争可能是有利的。它促进健康竞争，迫使企业增加研发支出，更明智地分配资本，并减少开发有效人工智能系统所需的时间。然而，竞争也有黑暗的一面。公司可能会被鼓励偷工减料，忽视重要的安全程序。更危险的是，比赛让参与者相互竞争。为了确保积极的结果，我们需要企业和国家之间的广泛合作。全行业的协作和透明文化使研究人员能够更有效地解决问题并确定最佳实践。人工智能带来的挑战的规模和范围如此之大，以至于一个研究团队不太可能取得实质性进展。然而，共享关注点和数据的研究人员联盟有更好的机会。信息共享和产生解决方案的伙伴关系是我们避免构建有偏见、可能被敌对行为者滥用或容易发展颠覆倾向的人工智能系统的唯一方式。人工智能社区已经在这方面做出了令人尊敬的努力；像 OpenAI 和人工智能促进协会这样的非营利组织正在阐明人工智能的风险，并动员研究人员就潜在的解决方案进行合作。脸书和谷歌等科技公司的研究人员经常在会议上展示他们的工作，有时甚至会发布源代码，以便其他人可以复制他们的工作。然而，我们不应该担心参与这些合作努力的各方，而应该担心那些弃权的人。

人工智能竞赛不是一个可能在未来几年发展的抽象情况；我们已经听到各种言论，并目睹了由争第一的愿望所引导的政策决定。2017 年，俄罗斯总统弗拉基米尔·普京在与俄罗斯学生交谈时宣布，“谁成为(人工智能)的领导者，谁就将成为世界的统治者。”许多其他国家已经宣布人工智能是战略性的国家优先事项，并提供大量资源来支持他们对人工智能领导力的愿景。过去几年，中国在这一领域积累了一系列举措。这包括国务院 2017 年发布的“下一代人工智能发展计划”，该计划设定了中国到 2030 年成为人工智能世界领导者的目标。这些举措不是孤立的努力。在过去的十年里，中国已经成为人工智能和相关领域的领导者。《泰晤士报高等教育》报道称，在 2011 年至 2015 年期间，中国发表了超过 4.1 万篇关于人工智能的论文，几乎是美国的两倍。随着该行业的成熟，我们不应惊讶地看到更多国家采取保护主义措施来保护国内技术和知识产权。国会议员目前努力扩大美国外国投资委员会(Committee on Foreign Investment in u . s .)的职权范围和资源，该委员会负责审查外资收购美国企业的提议，这可能是更激进措施的先兆。

那么，有没有什么方法可以减缓比赛的速度，并确保玩家对安全有足够的重视呢？区分放慢和停止竞赛是很重要的。停止比赛将被证明是困难的和适得其反的。相反，我们应该引导这场竞赛并确立最佳做法。美国目前围绕自动驾驶汽车的监管框架可能提供了一个如何在国内层面指导范式转变技术发展的例子。通过对各州的自愿指导和技术援助相结合，国家公路交通安全管理局使各州能够制定渐进的法规，允许自动驾驶汽车的安全发展。违反法规或不安全事件可能导致公司的权利被取消，例如今年早些时候，亚利桑那州在一起致命事故后命令优步暂停测试其自动驾驶汽车。像这样的惩罚行为阻止了偷工减料和忽视安全标准。

然而，像这样的模型并不能解决国家之间更普遍、更有害的竞争。如果中国抄近路，美国和其他国家将有额外的动机采取更宽松的监管，以公平对待本国科技公司之间的竞争。这种监管不对称已经存在。瑞士瑞信银行高管陶冬预测，中国将赢得人工智能竞赛，很大程度上是因为一个原因:中国缺乏关于数据保护的“严肃法律”，这使得公司可以不受限制地访问大量消费者数据，这些数据是微调机器学习算法所需的。由于监管不对称和全球竞争，国内解决方案是不够的；安全的人工智能必须是一个全球共享的优先事项。

当从人工智能带来的挑战中寻求安慰时，我们经常用工业革命和核武器来安慰自己。我们已经利用技术独创性和法律创新来限制或克服这些发展带来的危险，我们可以再次这样做，这是一种思路。然而，这些并不完美的类比可能会让我们陷入一种危险的自满状态。这并不是说制造恐慌是有成效的——无论我们喜欢与否，我们都必须接受人工智能正在到来，并将在我们的生活中发挥实质性作用。但是，我们不应该满足于我们社会的荣誉，并假设让企业和国家自己去解决这个挑战。当前的体系结构鼓励走捷径，强调进步重于安全。期望大多数人工智能系统拥有强大的安全标准，有点像在碗里混合沙拉的所有必要成分，然后期待一个汉堡。我们肯定会失望的。