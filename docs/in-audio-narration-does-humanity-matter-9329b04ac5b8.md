# 音频旁白中，人性重要吗？

> 原文：<https://medium.datadriveninvestor.com/in-audio-narration-does-humanity-matter-9329b04ac5b8?source=collection_archive---------10----------------------->

[![](img/0006070f963758f8322ad58bbbba178d.png)](http://www.track.datadriveninvestor.com/1B9E)

随着文本语音转换和人工智能技术的进步，人类声音的力量仍有存在的理由

由 Hayley Grgurich 为 Gyst Audio 创作

![](img/7fb54698a84f354ce5db61c950bccf2f.png)

Photo by [Siddharth Bhogra](https://unsplash.com/photos/k3kdc5MQYyk?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/wearing-headphones?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

2018 年 5 月初，谷歌首席执行官桑德尔·皮帅站在大屏幕前，全神贯注的节日人群演示了一个机器人声音[听起来非常逼真](https://www.theverge.com/2018/5/8/17332070/google-assistant-makes-phone-call-demo-duplex-io-2018)。这是谷歌助手的声音，观众观看了它打电话给沙龙的详细过程，进行了听起来很自然的对话，并为它的“客户”丽莎预订了理发。

观看视频时，当机器人向电话另一端毫无戒备的人类抛出“嗯嗯”之类的对话填充语时，你可以听到人群中发出的集体开心的笑声。感觉就像是在炫耀它有多逼真。

像谷歌助手这样的计算机生成语音技术正在迅速发展，其潜在的应用非常广阔。有谷歌支持的个人助理用例，但也有机会为视障人士改善资源，包括更容易、更快和更便宜地制作电视和电影中的视觉效果的音频描述，或者通过点击按钮将书面文本翻译成声音文件。

在一个机器人不仅可以像我们一样说话，甚至可以像我们一样回应的时代，在音频中使用人类的语音还有价值吗？或者我们应该继续“让谷歌去做”吗？

科学是混合的。[发表在*当代生物学*上的一项研究](https://www.ncbi.nlm.nih.gov/pubmed/14738732)发现，当人们做一个动作或看另一个人做那个动作时，会有相同的神经反应。然而，当人类观看机器人表演动作时，这种神经反应并不存在。

鉴于编码运动时对生物模型的选择性偏好，我们的大脑是否也能区分人类和人工语音？

圣路易斯华盛顿大学的一项研究发现，无论是听人声还是听电脑，听众对内容的注意力或对细节的记忆没有显著差异(尽管如果他们在听旁白的同时阅读文本，每个人的记忆都会增强。说起来，你可以在这里听听这篇文章的[人声版](https://app.gystaudio.com//blog)。

尽管如此，发表在专业翻译杂志 上的一项研究发现，视障参与者在评价录像时，对电视和电影的音频描述表现出适度的偏好。当在一份测试后问卷中被问及对于音频描述，他们更喜欢人声还是合成声音时，偏见更加明显:整整 81%的人说他们喜欢人声。

尽管已经很好了，但我们似乎还是忍不住要听计算机说话，听听缺少了什么。缺少的是灵魂。缺的是感觉。缺的是理解。也许不止一种方式。

Arjen Stolk 是伯克利 Knight Lab for cognitive neuroscience research 的博士后研究员，他描述了[的发现，该研究是他与人合著的](https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(15)00286-7?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS1364661315002867%3Fshowall%3Dtrue)关于人类大脑在纯语言范围之外用于交流的额外信息。

“人类会考虑他们认为相互了解的东西，”斯托尔克说。“随着互动的展开，他们不断地寻找并提供这种‘相互理解’的证据，从而形成一个独特而动态的‘共享认知空间’，不断地被他们过去的互动和当前的背景所告知。”

“相比之下，”斯托尔克说，“苹果的 Siri 等虚拟助手使用的算法仅限于文字所包含的信息。这些信息不依赖于我们认为我们都知道的东西，而是依赖于从许多文本中抽象出来的统计规律。”

因此，人类交流超越了单纯的语言交流；它考虑一个空间，创造一个环境，甚至利用对过去不相关事件的回忆来帮助参与者不仅完全理解所说的内容，而且理解其含义。

它还涉及计算机语音永远不会涉及的东西:生活体验。在一篇关于画外音叙述艺术的文章中，唐梓诺·吉伯特，500 多本有声读物的讲述者说，就像“她低声说”或“他大声喊”这样的声音提示一样，她扫描新材料寻找角色的物理描述来丰富她的阅读。

“我在寻找每个角色关于他们自己或其他角色的任何说法，包括他们的身体描述，这影响了某人的声音，”她说。“一个背部严重驼背、双手像鸟一样摆动的老年女性，听起来会与年轻时是首席芭蕾舞演员、但仍将头发向后挽成完美发髻的老年女性截然不同。”

对像 Medium 这样的公司来说，它为顶级文章制作人声版本； [Gyst 音频](https://gystaudio.com/)；和 Audible(它为一些标题提供人类叙述，为其他标题提供计算机生成的文本到语音的叙述)，这种额外的人类接触胜出。虽然你没有与在 [Gyst 应用](https://gystaudio.com/partnership)中朗读文章的人类讲解员进行对话，但该公司的创始人 Osa Osarenkhoe 仍然强烈地感觉到，真实的人类声音可以增强聆听体验。

“人声更好，”Osarenkhoe 说。“它们更光滑。机器语音几乎都有自己的方言。当你听机器朗读时，你必须在大脑中将单词转换回文本，然后重新朗读。”

显然，对于音频出版商来说，在人声和文本语音自动化之间做出选择并不容易。文本到语音的转换在更大范围内更便宜。它也更快，因为计算机不会出错或请病假。即便如此，在计算机能够以识别的热情、理解的共鸣以及身体的质地和音色来处理材料之前，对于顶级出版商和他们的听众来说，似乎没有什么可以替代真实的东西。

# DDI 特色数据科学课程:

*   [**用于数据科学的 Python**](http://go.datadriveninvestor.com/intro-python/mb)
*   [**深度学习**](http://go.datadriveninvestor.com/deeplearningpython/mb)
*   [**数据可视化**](http://go.datadriveninvestor.com/datavisualization/mb)

**DDI 可能会从这些链接中收取会员佣金。我们感谢你一直以来的支持。*