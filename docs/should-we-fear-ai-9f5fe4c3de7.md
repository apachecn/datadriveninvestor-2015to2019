# 我们应该害怕 AI 吗？

> 原文：<https://medium.datadriveninvestor.com/should-we-fear-ai-9f5fe4c3de7?source=collection_archive---------5----------------------->

![](img/e88168180ed7f48e6da2b5654ead8558.png)

Do we only think we are save or do we really have everything under control? Photo by [Jared Rice](https://unsplash.com/photos/k3pYa0CDLl0?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/shark?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

近年来，由于计算能力的巨大增长、大量可用的数字信息和解决特定问题的新方法，人工智能已经变得无处不在。随着公众对它的兴趣和有利可图的商业潜力，资金在 20 世纪 70 年代停止后再次暴涨。随着人工智能如今的知名度及其异常广泛的能力，关于其目前的发展状况和未来扩张的危险，有许多错误的指控正在传播。这些怀疑有根据吗？AI 的未来到底是什么样子的？

# **什么是 AI？**

人工智能是一套范式和算法，试图从现实世界收集的数据中发现模式，并将这些模式转化为对未来未知情况的有用预测。在初始学习过程完成后，人工智能可以根据它自己学习的各种因素做出决定。

在有监督的机器学习的情况下，象征基础事实的输入输出对是训练的起点。所选择的机器学习算法通过进行增量调整来优化自身，以正确地传递期望的输出。这样做了至少几百万次之后，你就可以对现实世界中类似的物品进行评估或分类了。关键的部分是人工智能自己决定输入的哪些属性是重要的。它可能是一个真实的特征，对这个类来说是独一无二的，也可能只是你无意中选择了某种类型的输入输出对而引入系统的偏见。例如，如果你教一个人工智能如何区分狗和狼，如果背景部分是雪，它可能会说这是一张狼的照片。这就是所谓的偏差，用来说明人工智能系统的好坏取决于用来训练它的数据。

当你有大量你一无所知的数据时，可以使用另一种方法。在这些情况下，无监督学习是 goto 解决方案。人工智能试图找到有用的模式和聚类，同时通过数百万或数十亿的条目。之后，它可以给你一些有价值的链接，比如一些经常组合在一起的点等等。这是亚马逊和其他零售商根据他们了解的关于你的各种因素给你提供相关建议的方式。

# **人工智能能做什么？**

现在的大多数人工智能都异常狭隘。有些可以自动驾驶汽车，有些可以预测你下一次网上购物，有些可以分类绿色和红色的苹果，有些可以识别你拍的照片上的人是谁。它也被称为“弱人工智能”，是我们迄今为止实现的唯一人工智能形式，并且只专注于单个领域。然而，在分配给它们的任务中，它们大大超过了人类。

在仓库库存管理这样的案例中，问题不在于人工操作的工作会不会消失，而在于消失的速度有多快。机器人比人类更便宜，不用吃饭，不用睡觉，不用休息，提供更精确的工作，而运营成本只是人类的一小部分。人工智能在那里发挥的作用不是机器本身，它形成了一个完全独立的工程领域，而是所有这些实体的通信、协调和共享智能，通过协作提高效率是主要关注点。

# **当前人工智能的局限性**

但人工智能还不是最重要的解决方案。埃隆·马斯克(Elon Musk)关于纯机器人工厂的伟大计划戏剧性地失败了，因为他低估了人类劳动力的灵活性。他最初的想法导致了许多延误，成本飙升，几乎让公司破产。主要问题是，在与松散和可弯曲的部件进行交互方面，控制机器人的人工智能算法远不如人类灵活。

由于世界上最先进的公司之一无法创造一个可以在受控环境中抓住悬在空中的软管的人工智能，因此在我们中间广泛传播通用机器人的希望就更小了。在最不利的环境中，大量可能的场景使开发变得复杂，以至于结果不明确，整个开发从商业角度来看不再可行。

尽管如此，像波士顿动力公司这样的公司正在制造像人和狗一样的机器人，它们可以穿越困难的地形，即使在意外事件将它们撞倒在地的情况下，也能保持移动。再加上一些已经存在的人工智能操作的武器，你就有了大多数人害怕的东西——自动杀人机器。抛开道德和政治不谈，就目前的技术而言，这种融合是极其不可靠的。然而，这里我们仍然谈论狭义的人工智能，它只接受人的命令，并遵循一个设定的目标。

# **人工通用/超级智能(ASI 阿西)**

题目中提出的问题的意思是，我们是否应该害怕 AI 这个人类物种。人工通用智能(AGI)是一个描述一种能够跨领域优化的人工智能的术语。理论上，它应该能够学习和做任何事情，只是时间和计算能力有限。当我们问自己在这种情况下会发生什么时，就会产生担忧。人工智能会尊重我们和我们的需求吗？我们将能够控制它还是它将是主权的？它会表现出同情和共鸣还是会像我们看蚂蚁一样？

虽然我们不能肯定地说，科学家们预计，一个真正的 AGI 将能够在几个小时或几天内超越到人工超级智能(ASI)。这在尼克·博斯特罗姆的《超智能》一书中有很好的解释。这种巨大的潜力意味着它将会是这个星球上最聪明的东西。值得注意的是，一旦开启了一个 ASI，可能就无法再关闭了。现在的软件、硬件甚至物理限制甚至都无法阻止有能力、有决心的黑客。对先进的东西抱有这样的希望纯粹是无知。

考虑到这一点，我们没有任何直接的隔间，到底会发生什么，但历史，基于殖民化，表明要么缓慢消除或全球奴役人类。哥伦布，这可能听起来可怜和严峻，但理论上是一个可能的解决方案，如果我们什么都不做。关于我们在这个新的世界秩序中的必要性和有用性的问题将由新创造的上帝来回答。我们可能会被视为坏人，取代了失去平衡的一切。这并不是说它会对我们有负面的感觉，而是我们宁愿留在 ASI 实现其目标的道路上。

让我们假设我们创造的 ASI 对人类是友好的。给它几天时间，它可能会解决我们所有的问题。乌托邦！最终目标达到了！现在呢？没什么可讨论或研究的。人类会怎么做？在一项受欢迎的实验中，一个人为创造的老鼠乌托邦不可避免地将它们推向灭绝，因为它们在达到顶峰后停止进食和繁殖。陀思妥耶夫斯基在《地下笔记》中提出了这一点，如今在西方的观察表明人类也有同样的结果。乐观主义者说 ASI 也会发现这个解决方案的问题。

第三种选择是一个不关心我们的矛盾的人工智能。它可以帮助我们停止战争，与自然和谐相处，但不能解决我们所有的问题。它可能和我们看待野生动物的方式一样。ASI 可能会发展自己的太空舰队并殖民银河系。它可能是地球上的上帝，只在需要的时候干预，让人类做他们自己的事情。在这种情况下，我们的未来高度依赖于 ASI 的道德和价值观。

# **建立道德指南针**

建立和校准道德指南针可能是人类曾经或将面临的最大问题。这个决定的精确性的纯粹后果要么将我们提升到神一样的地位，要么结束我们。这不仅会给开发人工智能的软件工程师带来巨大压力，也会给哲学家、政治家、心理学家和更多人带来压力。

一些人提出简单的指导方针来保证人类的安全。阿西莫夫臭名昭著的规则抬高了人类的生活，赋予它超越的价值。但是这个模型在政治、经济、伦理方面有很大的差距，而且容易被误解，这对于控制像 ASI 这样复杂的东西来说是不够的。

想象一下，如果我们告诉人工智能让人类笑得更多。预期的结果将是焦虑和抑郁率降低，更多的社会接触和更少的孤独感。然而，ASI 可能会找到一种更有效的方法，绕过改善我们生活的整个喧嚣，直接用电控制我们的面部肌肉，使它们形成微笑。这个例子是用来说明准确的目标设定与明确的道德边界相结合的必要性。

看看我们当前的政治形势，应该很清楚，在一个有争议的话题上达成结论性的共识几乎是不可能的。政治应该是左翼和右翼之间的持续对话，没有哪一方是完全正确或错误的，确保尽可能多的人的意见和关切得到听取，迫使整个社会采取适当的行动，使每个人的生活至少好一点。将所有权力交给一个实体会引发对独裁、平等、特权等诸多问题的担忧。

然后是不准确执行的可能性，不可预见的发展，甚至通过恶意的意图或通过监督一些关键因素增加偏见。道德和伦理领域应在此发挥主导作用，开展公开讨论，缓解紧张局势，使发展进程变得透明，并为绝大多数人所理解。来自不同领域的专家和门外汉可以根据人工智能为我们提供的帮助，提出鼓励美好、充实和有意义生活的解决方案。

# 但是还有很长的路要走

一些人工智能已经可以比人类看得更清楚，并正确地标记图像上显示的内容。但是你的感官过滤了大量的信息。你可能没有注意到天花板的颜色或者你附近的人的衣服。你可能已经将你的通勤自动化到了一个你可能会忽略它的大部分的程度。然而，你可以用来描述你周围环境的事实是无限的。选择注意什么以及某件事有多重要绝不是小事，尽管人类很容易做到这一点。手头情况的具体情况、优先事项、目标和许多其他事情一起形成我们的注意力，这决定了我们标记为“值得我们花时间”的信息。

此外，我们对人脑是如何工作的知之甚少。虽然我们的硬件远远超过我们头脑中所携带的东西，但模拟类似的东西在不久的将来甚至是不可想象的。计算机科学家取得的更大进展是模拟蠕虫的大脑，这甚至比不上人的大脑。

毫不奇怪，这使得 AGI 的发展成为一个多方面的问题，需要从伦理学、心理学、哲学、政治学、经济学、生物学和许多其他领域寻求解决办法。有多种测试和挑战，如臭名昭著的图灵测试、Winograd 模式挑战、Marcus 测试仍未解决，即使在我们当前的开发中，也没有迹象表明它们会很快通过。

在那之前，我们有更大的问题要解决。战争、饥饿、不平等、气候变化、食物短缺、失业率只是其中的几个例子。我们今天投入的让我们免受 AGI 病毒侵袭的假设和想法，在不久的将来可能会变得与新的发现无关。保持适度的怀疑态度，从不同的视角积极研究这个领域，应该足以确保我们不会创造出自己版本的终结者。如此接近某个巨大的目标应该会激励我们尽最大努力。到那时还有很长的路要走，但当它发生时，肯定会为时已晚。