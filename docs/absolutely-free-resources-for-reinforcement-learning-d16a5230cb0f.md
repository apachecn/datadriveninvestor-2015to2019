# 强化学习的绝对免费资源

> 原文：<https://medium.datadriveninvestor.com/absolutely-free-resources-for-reinforcement-learning-d16a5230cb0f?source=collection_archive---------1----------------------->

![](img/1dd611749d6d20e3c420da59591cec1a.png)

## 强化学习的免费完整课程

强化学习在 2016 年 Deep Mind 的 AlphaGo 击败世界冠军围棋选手李·谢多尔( [**AlphaGo 对李·塞多尔**](https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol) )之后，成为数据科学中的蓝眼领域。围棋，这个古老的棋盘游戏被电脑程序认为很难，但在这之后一切都变了。此后，人们对该领域产生了极大的兴趣，但学习内容很少。萨顿和巴尔托 [**的书**](http://incompleteideas.net/book/bookdraft2017nov5.pdf) 仍然是最好的来源，但带有一些互动解释的课堂内容将有助于任何想深入这个令人兴奋的机器学习和人工智能领域的人。

这是互联网上免费提供的内容汇编。包含**完整课程**的内容仅被视为该列表的一部分。这些没有以任何特定的顺序列出。如果有的话，我会列出课程名称、主要教师、由哪个机构提供以及年份。

[](https://www.datadriveninvestor.com/2019/03/03/editors-pick-5-machine-learning-books/) [## DDI 编辑推荐:5 本让你从新手变成专家的机器学习书籍|数据驱动…

### 机器学习行业的蓬勃发展重新引起了人们对人工智能的兴趣

www.datadriveninvestor.com](https://www.datadriveninvestor.com/2019/03/03/editors-pick-5-machine-learning-books/) 

# **强化学习入门|大卫·西尔弗|深度思维| 2015**

这应该是任何对强化学习感兴趣的人的第一门课。虽然它可能看起来有点过时，但对于一个坚实的基础来说，你需要通过这个开创性的课程，不是别人，正是强化学习的传奇人物大卫·西尔弗教授的。课程涵盖以下主题(可通过链接参考幻灯片):

讲座 1: [强化学习简介](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/intro_RL.pdf)

讲座 2: [马尔可夫决策过程](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/MDP.pdf)

第三讲:[动态规划规划](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/DP.pdf)

第四讲:[无模型预测](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/MC-TD.pdf)

第五讲:[无模型控制](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/control.pdf)

第六讲:[价值函数逼近](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/FA.pdf)

第七讲:[政策梯度方法](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/pg.pdf)

第八讲:[整合学习与规划](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/dyna.pdf)

第九讲:[勘探开发](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/XX.pdf)

第十讲:[案例分析:经典游戏中的 RL](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/games.pdf)

# **CS294 深度强化学习|谢尔盖·莱文|加州大学伯克利分校| 2018**

这是强化学习的最佳课程之一。涵盖许多高级主题。Sergey Levine 是该领域的领先专家，用足够的例子和数学细节对所有主题进行了非常详细的解释。讲座列表:

第 01 讲简介和课程概述
第 02 讲监督学习和模拟
第 03 讲张量流和神经网络复习课(笔记本)
第 04 讲强化学习介绍
第 05 讲策略梯度介绍
第 06 讲演员-评论家介绍
第 07 讲价值函数和 Q-学习
第 08 讲高级 Q-学习算法
第 09 讲高级策略梯度
第 10 讲最优控制和规划
第 11 讲基于模型的强化学习
第 12 讲高级模型学习和图像
第 13 讲通过模仿其他策略学习策略
第 14 讲概率和变分推理入门
控制
讲座 16 逆强化学习
讲座 17 探索第一部分
讲座 18 探索第二部分
讲座 19 迁移学习和多任务学习
讲座 20 元学习
讲座 21 并行性和 RL 系统设计
讲座 22 高级模仿学习和开放问题
讲座 23 客座讲座 Craig Boutilier
讲座 24 客座讲座 Gregory Kahn
讲座 25 客座讲座 Quoc Le & Barret Zoph

# **CS234:强化学习| Emma Brunskill|斯坦福| 2019**

这是斯坦福大学 2019 年开设的新课程。有关更多详细信息和幻灯片，请访问课程网站:

[http://web.stanford.edu/class/cs234/schedule.html](http://web.stanford.edu/class/cs234/schedule.html)

# **高级深度学习&强化学习| Hado Van Hasselt | Deep Mind | 2018**

这是 Deep Mind 提供的另一门课程。该课程有两个交错的部分，这两个部分在课程结束时汇合。一部分是关于使用深度神经网络的机器学习，另一部分是关于使用强化学习的预测和控制。这两股力量通过深度强化学习结合在一起，深度神经网络在强化学习环境中被训练为函数逼近。

# **CS885** **强化学习| Pascal Poupart|滑铁卢大学| 2018**

本课程由 Pascal Poupart 教授，他是强化学习领域的知名人士。课程非常详细，涵盖了许多高级主题。有关该主题的更多详细信息，请参考下面的链接。

[https://cs . uwaterloo . ca/~ ppou part/teaching/cs 885-spring 18/schedule . html](https://cs.uwaterloo.ca/~ppoupart/teaching/cs885-spring18/schedule.html)

# **深度 RL boot camp | Pieter Abbeel | Berkeley | 2017**

强化学习训练营，由该领域的许多知名专家讨论的主题。

*   核心讲座 1 MDPs 和精确解方法介绍— Pieter Abbeel ( [视频](https://www.youtube.com/watch?v=qaMdN6LS9rA) | [幻灯片](https://drive.google.com/open?id=0BxXI_RttTZAhVXBlMUVkQ1BVVDQ))
*   核心讲座 2 基于样本的近似和拟合学习— Rocky Duan ( [视频](https://www.youtube.com/watch?v=qO-HUo0LsO4) | [幻灯片](https://drive.google.com/open?id=0BxXI_RttTZAhREJKRGhDT25OOTA))
*   核心讲座 3 DQN +变体— Vlad Mnih ( [视频](https://www.youtube.com/watch?v=fevMOp5TDQs) | [幻灯片](https://drive.google.com/open?id=0BxXI_RttTZAhVUhpbDhiSUFFNjg))
*   核心讲座 4a 政策梯度和演员评论家——彼得·阿比尔([视频](https://www.youtube.com/watch?v=S_gwYj1Q-44) | [幻灯片](https://drive.google.com/open?id=0BxXI_RttTZAhY216RTMtanBpUnc))
*   核心讲座 4b Pong from Pixels—Andrej kar pathy([视频](https://www.youtube.com/watch?v=tqrcjHuNdmQ) | [幻灯片](https://drive.google.com/open?id=0BxXI_RttTZAhTUpqUFdEZ3BXNFE))
*   核心讲座 5 自然政策梯度、TRPO 和 PPO —约翰·舒尔曼([视频](https://www.youtube.com/watch?v=xvRrgxcpaHY) | [幻灯片](https://drive.google.com/open?id=0BxXI_RttTZAhMVhsNk5VSXU0U3c)
*   核心讲座 6 深度 RL 实验的具体细节——约翰·舒尔曼([视频](https://youtu.be/8EcdaCk9KaQ) | [幻灯片](https://drive.google.com/open?id=0BxXI_RttTZAhc2ZsblNvUHhGZDA))
*   核心讲座 7 SVG、DDPG 和随机计算图—约翰·舒尔曼([视频](https://youtu.be/jmMsNQ2eug4) | [幻灯片](https://drive.google.com/open?id=0BxXI_RttTZAhRnlabHNRUFJ5cG8))
*   核心讲座 8 无衍生工具方法—陈品山([视频](https://youtu.be/SQtOI9jsrJ0) | [幻灯片](https://drive.google.com/open?id=0BxXI_RttTZAhSDN0RWlpTnZKblU))
*   核心讲座 9 基于模型的 RL — Chelsea Finn ( [视频](https://youtu.be/iC2a7M9voYU) | [幻灯片](https://drive.google.com/open?id=0BxXI_RttTZAhRTBqQmc5R0pGQlE))
*   核心讲座 10a Utilities — Pieter Abbeel ( [视频](https://youtu.be/yA6wXERug70) | [幻灯片](https://drive.google.com/open?id=0BxXI_RttTZAhNXZKdVZqVUFyTkE))
*   核心讲座 10b 逆 RL —切尔西·芬恩([视频](https://youtu.be/d9DlQSJQAoI) | [幻灯片](https://drive.google.com/file/d/0BxXI_RttTZAhNjN4SnNYYldqTjQ/view?usp=sharing))
*   前沿讲座 I:深度 RL 的最新进展、前沿和未来— Vlad Mnih ( [视频](https://youtu.be/bsuvM1jO-4w) | [幻灯片](https://drive.google.com/open?id=0BxXI_RttTZAhakZJcUpFVzk4S2c))
*   前沿讲座二:深度研究的最新进展、前沿和未来——谢尔盖·莱文([视频](https://www.youtube.com/watch?v=lYU5nq0dAQQ) | [幻灯片](https://drive.google.com/open?id=0BxXI_RttTZAhbkFZblhaZ3QxR3c))
*   TAs 研究概述([视频](https://www.youtube.com/watch?v=C4xreqGNGhs) | [幻灯片](https://drive.google.com/open?id=0BxXI_RttTZAhRklVTHNlTHdvTFU)

# 强化学习| Balaraman Ravindran| Nptel | 2016

这是一门通过 NPTEL 提供的精彩课程，由 Balaraman Ravindran 教授。课程在很大程度上遵循萨顿和巴尔托的书，并对强化学习的一些复杂领域进行了深入的解释。

当有新的免费资源可用时，我会及时更新这篇文章。在那之前，希望你能踏上强化学习的旅程。

## 感谢阅读。可以联系我@ [LinkedIn](http://www.linkedin.com/in/baijayantaroy) 。