# 聊天机器人的困境

> 原文：<https://medium.datadriveninvestor.com/the-dilemma-of-the-chatbots-99746646edd0?source=collection_archive---------8----------------------->

![](img/df197efa37224d2aeb987cd202d143b6.png)

目前，像 Sir、Alexa、Cortana 之类的聊天机器人既是数字网络的象征，也是先驱。他们充当信息提供者、数据搬运工、数字管家和顾问。通过提供智能产品，聊天机器人对可理解的现实空间的影响越来越大。通过实现人工智能，聊天机器人脱离了单纯的算法，变得具有适应性。进化是可以想象的。未来，他们的成功将不再取决于技术可行性。但是，开发、使用和传播的限度将由人类赋予它们何种能力以及由谁对它们的决定负责来确定。

为了更好地评估人工智能控制的机器人的效果，可能需要解释三个相关术语:*图灵测试*、*人工智能*和*社交机器人*。

# **图灵测试**

图灵测试是艾伦·图灵在 1950 年提出的，目的是测试机器表现出与人类相当的智能行为的能力。来自早期计算机科学分支*人工智能*的传奇测试为计算机时代重新激活了思维机器的神话。

在这个测试过程中，一个人类提问者通过键盘和屏幕与两个他不认识的对话伙伴进行对话，看不到也听不到他们。对话伙伴之一是人，另一个是机器。两者都试图让提问者相信他们在思考人类。如果提问者在密集提问后不能明确说出两者中哪一个是机器，那么机器已经通过了图灵测试，并被假定为机器具有与人类相等的智力能力。

对于为什么图灵测试不适用于智力测定，已经提出了许多论点:

**“图灵测试只检查功能性，不检查是否存在意向性或意识。约翰·塞尔在他的《中国房间的思想实验》中阐述了这一论点。图灵在设计他的测试时已经意识到了这个问题。但是他认为这个测试也可以作为意识的证明。而塞尔拒绝了。”**

(参考:维基百科，2018 年 1 月 4 日状态)

# **AI——人工智能**

今天，1956 年关于人工智能的*达特茅斯夏季研究项目*被视为人工智能*一词的诞生时刻。在其供资提案中，它制定了*

学习的每一个方面或智力的任何其他特征在原则上都可以被精确地描述，以至于可以制造一台机器来模拟它。人们将试图发现如何让机器使用语言，形成抽象概念，解决现在留给人类的各种问题，并自我完善。”

(参考:斯坦福大学，2018 年 1 月 4 日状态)

自动化、语言处理、神经网络和创造力是提案中的主题。*深度学习*已经在*自强的标题下勾勒出来了。*

*人工智能*的研究领域是通过机器/计算机/计算机程序处理人类思维的模拟、模仿和自动化。问题是，计算机可以变得多么智能、自主、人形或有自我意识？在某些领域，计算机已经超越了人类:IBM 的国际象棋计算机*深蓝*在 1996 年击败了国际象棋世界冠军加里·卡斯帕罗*沃森*在智力竞赛节目 *Jeopardy 中击败了他的两个人类对手！*2011 年和 2016 年，谷歌的 *AlphaGo* 在围棋棋盘上击败了卫冕世界冠军 Lee Sedol。乍一看似乎平淡无奇，但考虑到处理的复杂性，这是值得注意的，甚至在人工智能诞生的时候都没有想到。

# **社交机器人**

**“社交机器人是存在于社交媒体中的机器人，又名软件机器人或代理。他们喜欢并转发微博，他们写作并评论，因此拥有天生的语言能力。它们还可以充当聊天机器人，从而与用户同步交流。”**

(参考:施普林格·加布勒出版社(ed。)，Gabler Wirtschaftslexikon，关键词:社交机器人，或者在网上:[https://Wirtschaftslexikon . Gabler . de/definition/social-bots-54247/version-277296](https://wirtschaftslexikon.gabler.de/definition/social-bots-54247/version-277296)(2018 年 11 月 6 日状态)

Google Hangouts (以前的 *Google Talk* )有望彻底改变呼叫中心。聊天机器人应该成为标准，只有当聊天机器人不再知道该做什么时，人类才会填补。

# **社交机器人误入歧途**

只要*社交机器人*是可识别的，就没有问题。但是现在的趋势是*社交机器人*伪装成人类(有名字、资料和 vita)并根据设定的参数分析、生成和传播信息。他们的人工智能和语言能力以及写作技能功能越好，就越难解密他们真实的机器身份。*社交机器人*可以克隆自己，扮演不同的角色，执行命令。它们处理信息并根据程序和设定的意图做出反应。

因此，聊天机器人可以作为信息管理的倍增器，其力量和影响不可低估。他们像一支军队一样出发，带着特定的信息，这些信息可以不断变化地传播，但通过人工智能总是带着相同的意图和信息。

# **决策权**

为了避免做出用户无法做出的决定或在法律上有些困难的决定，语言助理会用借口(“我不明白你的问题”)或参考其他权威来帮助自己。每个人都可以通过提出一个简单的问题来测试当前的发展状态，例如自杀、紧急反应、感觉或指示，而不仅仅是一个电话或日历条目。但是用户将此解释为缺乏能力，因此导致沮丧和使用率降低，另一方面，这也是这些设备的制造商所不希望的。为了增强他们的市场影响力，制作人致力于开发越来越精确、决策能力越来越强的聊天机器人。这似乎也符合逻辑，因为只有拥有扩展决策权的聊天机器人才是真正对用户有帮助的，而不仅仅是噱头。发展方向是可以预见的。

# **开放式问题**

*   是否存在可定义和可调整的参数来评估和限制行动的后果？
*   聊天机器人的用户是否对所有聊天机器人的决定及其后果负责？
*   还是聊天机器人的生产商/提供商要对所有决定及其后果负责？
*   使用不当及其后果由谁负责？
*   智能设备的所有者/用户需要“监管职责”吗？
*   我们将来会购买保险来免除我们对聊天机器人错误决策的责任吗？
*   风险管理是否像股票交易一样必要(稳健->平衡->进攻性->投机->高风险)？
*   聊天机器人是否可以或者应该排除不可预测的灾难或者不可能的巧合？
*   超越单纯功利主义的定制数字伦理会是什么样子？

# **展望**

人工智能越是成为聊天机器人和数字网络的重要组成部分，困境就越是转向科技。在不久的将来，越来越多的*决策*将由机器*自己*别名*自主*做出。人类将只在预置的意义上选择参数。那么这或多或少就不是我们的困境了——即使我们感觉到了影响。我们移交的责任越多，我们尚未开发的其他机制将发挥更大的作用，因为否则它们将通过深度学习& Co 形成自己，并且它们的代码将不可见和不可控。

//*

2018 丹尼尔·谢德根

你可以在 www.designtheorie.net 找到这篇文章的德语版本

英语翻译由[米高梅技术合作伙伴](https://innovation-implemented.com/)提供