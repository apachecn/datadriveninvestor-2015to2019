# 人工智能“末日”可能看起来和我们想象的不一样

> 原文：<https://medium.datadriveninvestor.com/a-i-doomsday-might-look-different-than-we-think-75ff95db60c6?source=collection_archive---------2----------------------->

[![](img/328349432ad1241a9f8f8b8f0e878410.png)](http://www.track.datadriveninvestor.com/1B9E)![](img/b879b917644e89a591da379eb64e63ff.png)

Though distinct from Terminator-style “doomsday”, our technologies have already profoundly changed the way the world works. | [Source](https://www.huffpost.com/entry/thrive-through-the-workplace-experience_b_5452726)

我们都有一些想象，如果机器人接管，世界会是什么样子。好莱坞让我们的想象中充满了金属杀手的形象，他们只是想通过利用人性作为达到目的的手段来推进他们的事业。也许机器人甚至没有灭绝所有的人类，只是简单地耕种他们的生命能量来为他们的社会提供动力；编织一个复杂的模拟来分散人们的注意力。近年来，由于人工智能技术的进步和普及，这种恐惧再次出现。当人们的思想被耸人听闻的媒体的煽动性影响所煽动时，噩梦就会肆虐。我们开始生活在一个充斥着这种噩梦的世界里。

专家们最近一直在反击:告诉忧心忡忡的大众，人工智能距离经历任何末日临界点还有很长的路要走。相反，他们强调这些类型的世界末日场景是完全不现实的。他们声称，即使等到人工智能足够先进的时候，我们也已经为许多最坏的情况做好了周密的计划；最终在问题实现之前避开它。对机器人接管的担忧更类似于 20 世纪中期的担忧，想象核荒地生长的怪物会用它们发光、融化的第三只手臂恐吓温和的人类。

[](https://www.datadriveninvestor.com/2019/01/28/ai-creativity-deep-dream-comes-true/) [## 人工智能与创造力:梦想成真——数据驱动的投资者

### 人工智能总是让我着迷。不仅作为一套有用的工具，不断发展，而且作为一个…

www.datadriveninvestor.com](https://www.datadriveninvestor.com/2019/01/28/ai-creativity-deep-dream-comes-true/) 

我想说，尽管一些专家在说什么，人工智能确实有可能带来不可逆转的末日场景，而且已经在这样做了，并且正在跟随其他强大技术的脚步。从“正常”生活到我们是数字系统的傀儡的生活的转变将是如此的渐进，如此的微妙，以至于我们可能会被带着去兜风；一点也不知道。为了说明这一论点，我们应该看看三项技术:汽车租赁系统、社交媒体和核武器。每一个都提供了一个通向未来的入口，在那里人类没有任何线索知道它被人工智能所统治，并且反映了我们自己的世界，这可能会揭示它看起来比任何人想象的都更像未来的末日。

# 汽车租赁系统

最近有一次经历，期间出差要租车。这似乎是一个相当简单的交易:我在旅行前在线购买了租赁物，全额付款，这样更便宜，然后去取租来的车。我不知道我指定的取货地点并不是一个真正的租赁办公室。虽然它被列在选项的选择中，并且是我乘坐的火车的确切目的地，但这个办公室实际上以不同的名字存在于这条路的稍远处。

这完全打乱了我的租赁计划，我被迫等了一个半小时，与租赁办公室的员工、他的经理和呼叫中心的客户服务代表一起工作，而我的情况正在得到解决。他们都非常有帮助，我真的为他们感到难过，看到他们对计算机系统的失望，比我不得不等待这么长时间感到沮丧。如果这发生在计算机系统出现之前的日子里，位置差异可能会很快得到纠正，被承认为一个奇怪的事故，我会收到我的钥匙，然后上路。相反，在一个由数字官僚统治的世界里，租赁办公软件的规则是如此严格，以至于一个小小的错误(这是它首先允许的！)需要三名不同的员工参与，他们对系统的专业知识都很混乱。这就引出了一个笑话:拧上一个灯泡需要多少人？嗯，显然至少有四个，如果灯泡是一个国家的，计算机化的，严格执行规则的灯泡拧紧系统的一部分，错误信息只会让那些只想在房间里获得一些光线的人感到困惑。

> 我们已经生活在一个在很大程度上被电脑控制的世界里。

任何曾经在医生、医疗保险或任何其他大型全国性公司使用过计算机化系统的人，如果他们的软件设计不是一流的，都知道这些问题一直在发生。在许多情况下，数字系统承诺的便利陷入了糟糕的设计；因此使得该系统在给定的任何边缘情况下几乎不可能使用。

我在汽车租赁公司的经历比简单地说我们偶尔会设计糟糕的软件更能说明我们的社会。我们甚至可以说，因为这些类型的问题一直在出现，它们对我们来说已经变得不可思议地正常化了。随着时间的推移，我们不得不接受这样一个事实，即计算机系统经常发生故障，有时我们不得不花费数小时试图解决在没有严格软件的世界里永远不会出现的问题。

我们已经生活在一个在很大程度上被电脑控制的世界里。帮助我的员工完全屈从于顽固的租赁系统的意志。人类的聪明才智和力量变得毫无意义，因为计算机系统掌握着打开我汽车租赁的所有钥匙。因为世界逐渐开始实施数字化的官僚系统，每个人都只是随大流。在大多数情况下，对于他们的雇主是否在他们的工作中强加了一个破碎的、复杂的系统，一个低级别的雇员永远不会有任何发言权。少数人改变了世界的运作方式，我们都被迫慢慢接受这是我们的新现实。

不同的技术以不同的方式影响着我们。尽管汽车租赁问题令人沮丧，但当其他技术在其设计中表现出缺陷时，其结果可能更加有害。为了检验机器学习系统大规模实施的效果和反应，我们只需要看看令人沮丧的技术典范:社交媒体。

# 社会化媒体

过去几年，脸书、Instagram、Twitter 和 Snapchat 都卷入了丑闻；招致许多不同群体的批评。社交媒体平台从简单的联系老朋友或同学的网络转变为新闻和政治的日常中心。不幸的是，由于这些系统的本质主要是经济驱动的，通过网站上看到广告的眼睛数量计算的广告收入获利，社交媒体网络也有意将自己转变为上瘾的系统。通过向用户提供他们本来会喜欢的内容，利用他们现有的偏见，无耻的社交媒体用户体验到了意识形态的孤立和增强，因为他们只看到与他们自己一致的新闻或观点。

这种类型的机器学习旨在学习用户行为，以便将他们带到应用程序或网站，从而实现利润最大化，这对我们的社会产生了深远的影响。现在人们普遍认识到，过度使用社交媒体可能非常危险。人们会对脸书、推特或 Instagram 上瘾，并不断被与不同偏好的人完全不同的信息所包围。这导致许多用户采纳了与他们的政治或意识形态对立者截然不同的世界观，并认为他们完全基于他们在互联网上读到的“事实”。通过社交媒体使用的人工智能技术影响了如此多的个人观点，以至于社会话语作为一个整体发生了深刻的变化。

> 当只有少数人做出这样的重大决定时，大范围的社会效应会受到他们观点的严重影响——或者缺乏观点。

就像官僚的汽车租赁系统一样，使用社交媒体的人只是习惯了社交媒体网站收集他们的数据并扭曲他们的世界观。至少对于官僚系统来说，它们的错误和糟糕的软件设计有时会暴露出它们的缺陷，并表明数字系统不幸地、令人沮丧地控制了我们的生活。一般来说，社交媒体和机器学习推荐系统的设计都考虑到了有缺陷的结果。当它们正常工作时，它们会产生负面的社会影响。

当人们想到人工智能末日机器人控制我们的生活时，社交媒体系统就是那些末日机器人的画面永远不会出现。当然，我们并没有被残酷地违背自己的意愿，但在某种程度上，我们受到了社交媒体等管理我们生活的系统的严重限制。如果有什么东西影响了你的世界观，那么你的世界观就会根据你的信念控制你的行动。当人工智能研究人员消除对系统控制我们生活的恐惧时，我认为他们忽略了这一背景。通常情况下，计算机科学家和软件工程师在计算世界中过于孤立，以至于无法意识到他们的技术无时无刻不在引发深刻的社会变革。

令人难以置信的破坏性技术的大规模正常化对人类来说并不新鲜。在最近的记忆中，世界末日般的核军事化几乎已经成为司空见惯的“现实”。在越来越多的声音反对这种毁灭性能力扩散的地方，世界已经超越了这种概念最初的震惊——尽管这种技术构成的威胁在今天可能更加严重。

# 核技术

由于其潜在的破坏性能力，最初令人震惊的技术在缺乏围绕它们的对话时，很容易变得正常化。与仅仅一代或两代人之前相比，我们冷战后的世界不太关心毁灭世界的核武器的扩散和核条约的破坏。围绕核扩散的公开对话几乎已经停止；假设一个不可避免的核世界。事实是，核武器的扩散绝对不是不可避免的；正如一些世界领导人或技术人员可能建议的那样。发明家、创新者和国家领导人有能力根据他们的意识形态和目标选择技术进步的方式。一个追求军事霸权的美国总统比一个希望技术被用于更多人道主义目的的总统更有可能撕毁核武器条约。这些武器的传播被认为是“事情的本来面目”的唯一原因是因为所谓的领导人积极推动事情的本来面目；受利润、权力或者带着疯狂色彩的无知的驱使。

人工智能可能会遵循类似的道路。由于其不可思议的强大性质，限制或释放其潜在用途的决定，或将其融入社会的决定，肯定会首先落在政治和行业领导人的肩上。当只有少数人做出这样的重大决定时，大范围的社会效应会受到他们观点的严重影响——或者缺乏观点。在对这类决定进行一段时间的初步公众审查后，重要的话语很有可能会逐渐消失；只留下几个人来考虑许多人的命运。

> 认识到逐渐“末日”发生的可能性，并大声表达我们的担忧，是目前确保强大的技术行动者承担责任的最佳方式。

我们应该把人工智能看作是一种力量与核武器相当的技术。虽然这些系统的影响可能不会像使用核武器那样立即令人震惊，但使用人工智能系统的长期社会影响可能会像广岛和长崎的几代人一样深远。我们不能让世界变得如此适应人工智能的操纵，以至于只有少数人对它在世界上的影响有任何发言权或意见。受这些系统结果影响最大的人应该对如何开发和使用这些系统有永久的发言权。应该不断鼓励话语；甚至——尤其是——当它阻碍了短期利润或权力的获得。

正如核灾难导致的世界末日只是一个简单的错误一样，在不太遥远的未来，一个无法诊断的数字缺陷或少数程序员的未知错误也可能导致微妙的社会末日。那些对这两种技术做出决策的人是在有意识地做出选择，这些选择塑造了整个人类社会。当权者的任何不当行为、偏见或无知都可能带来专家认为基本不可能的世界末日。同样的专家正在成为正常化进程的一部分，这是非常危险的。这应该不断受到同样强大和多样化的声音的反击，呼吁谨慎行事。如果天平向正常化倾斜得太远，这可能意味着被一小撮不负责任的、潜在的恶意的少数人完全控制。

# 责任可能意味着生死

少数人潜在的无知或错误所造成的威胁只有一个合理的对应:多数人的缓解。技术专家不喜欢谈论这个问题，因为他们经常过于专注于自己的专业知识，而不会考虑那些生活受到潜在失败影响最大的人的意见。他们可以理解地想象，任何普通人都会对人工智能的决策有如此无知的看法，以至于他们认为只有技术专家有权塑造他们系统的开发和使用。

这种心态无疑是愚蠢的。那些生活被强大的技术改变得最多的人的观点是使任何对话公平的关键。如果核扩散者的家园被核武器彻底摧毁，他们肯定会对这项技术有不同的看法。如果脸书的高管发现自己在不知不觉中被算法操纵，他们可能会对贪婪的推荐系统的影响有不同的想法。那些有幸站在这些技术爆炸区之外的人往往缺乏远见或同情心，无法想象灾难性的后果会发生在他们身上。人工智能专家驳斥计算机系统的统治是正确的，他们驱散了终结者引发的歇斯底里，但如此彻底地驳斥我们的社会真的可以被计算机控制而不具备必要的人类理解能力的概念是错误的。

那些设计人工智能和机器学习系统的人必须计划足够程度的控制，以便任何潜在的灾难性影响都可以被轻松缓解。他们还必须承诺在做出重大决策时考虑“普通人”的观点。正如围绕脸书和 Twitter 的政治操纵丑闻引发了公众的愤怒，试图改变这些系统如何影响你的生活的唯一现有途径是变得愤怒。

由于在控制世界大部分地区的公司中缺乏公众代表，以及政府不愿意监管人工智能，现在问责的负担落在了普通人身上。认识到逐渐“末日”发生的可能性，并大声表达我们的担忧，是目前确保强大的技术行动者承担责任的最佳方式。如果技术专家或潜在监管者由于无知或傲慢而不听取大多数人的担忧，他们的选择可能意味着世界各地许多人的生死。

如果不从这个角度来看待机器学习技术，那就是在面对困扰世界的深刻问题时另辟蹊径。当然，机器学习或人工智能可能不会创造出不顾一切地通过复杂的模拟来控制我们的杀手机器人。然而，如果我们在分析这些系统时不小心，我们可能会在一个世界中醒来，我们的生活被少数人创造的机器所主宰，不容易回滚，我们甚至不知道我们被控制了多少，直到为时已晚。