# 算法的残酷和不透明

> 原文：<https://medium.datadriveninvestor.com/algorithmic-cruelty-and-opacity-5a2339e61c35?source=collection_archive---------9----------------------->

![](img/712d92c622d2089a85d371fd9394927c.png)

Photo by [Webaroo.com.au](https://unsplash.com/@webaroo?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

继[上一篇文章](https://medium.com/@sankarshan/the-national-ai-program-5a4f3f979a75)之后，自从我读了这篇推文(帖子)，我一直在思考和阅读自动化，尤其是 RPA。对于更多的背景，我也鼓励你去读读杰米[对此的看法](https://dhh.dk/2019/about-the-apple-card.html)。

随着越来越多的企业和组织采用机器人/远程过程自动化程序，用程序和算法取代人类，它带来了一定程度的不平等，除非你敏锐地察觉到这一点，否则很难理解。算法驱动的系统现在触及了我们日常生活的很大一部分。例如，小额/小额贷款；旅行和住宿的票价；保险索赔处理；企业提供的优惠和折扣；获得服务；获得信贷；获得医疗福利；使用交通工具/出租车只是其中的一部分。

[](https://www.datadriveninvestor.com/2019/03/22/the-seductive-business-logic-of-algorithms/) [## 算法诱人的商业逻辑|数据驱动的投资者

### 某些机器行为总是让我感到惊讶。我对他们从自己的成就中学习的能力感到惊讶…

www.datadriveninvestor.com](https://www.datadriveninvestor.com/2019/03/22/the-seductive-business-logic-of-algorithms/) 

我们被告知在生活中欢迎这种效率的营销术语是“人工智能驱动”或“人工智能驱动”。实际上，我们被要求感觉舒服的是这个黑盒系统，它吸收某些特定方面的数据，然后提供一个“解决方案”,或者说，对某些后续事件将发生的反应。不管受教育程度如何，也不管理解交易流程的能力如何，这种不透明的信息处理系统都会造成相当程度的迷惑和无助。自动化商业系统还通过消除所有可能的与人的互动来提高效率。与上一代系统(人们可以向人类寻求解释和/或理解程序内部)相比，人工智能系统(以及聊天机器人)能够实现一组看似精确的问题/回答，这些问题/回答是内置的，可能不包含所有不同的问题。

我们往往会忽略另一部分。而那就是一切都用“AI”或者说，“人工智能”的超载。从表面上看，这有助于企业显得更加现代、高效，并有可能让投资者相信，企业有能力不受雇佣更多员工的限制而不断发展壮大。除去行话，我们真正拥有的是“学习系统”。像所有搜索系统一样，为了能够创建与系统设计者预先确定的目标一致的解决方案，需要结构化和标签化的数据。这是这个故事的另一部分——工作作为原子任务被外包给无数人，这导致一个准备充分的数据集，系统设计可以在其上开始工作。

这些新系统的根本问题是缺乏一个补救系统，人们可以随意地说“哦！是制度”。Anupam Guha 提出了一个有效的观点来反对这种习惯，这种习惯将道德责任赋予无生命的系统，并在某种程度上，将这种服务的消费者推到了一堵冷漠的墙上。系统的不透明设计还导致一级支持人员不太注重实际理解问题，而是更多地投资于重复由于交易出错而生成的消息模板。

我们未能理解不平等的严重程度，当更多的消费者无法导航过程自动化系统(例如 IVR 或聊天机器人)试图响应过程自动化故障并因此陷入困境时，就会产生这种不平等。更加结构化和[可解释的人工智能](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence)运动非常适合将企业(和公司)的道德责任与系统设计中包含的技术责任联系起来。虽然越来越多的国家采用了 GDPR 的主旨，但也有一些要素，如可解释的系统，也需要通过监管流程来强制执行。否则，算法无意中的残酷将成为常态，成为我们尚未理解的压迫工具。