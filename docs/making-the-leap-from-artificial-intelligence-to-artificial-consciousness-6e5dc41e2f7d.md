# 从人工智能到人工意识的飞跃

> 原文：<https://medium.datadriveninvestor.com/making-the-leap-from-artificial-intelligence-to-artificial-consciousness-6e5dc41e2f7d?source=collection_archive---------0----------------------->

![](img/4583707d1155706ea868e78cfb0a6e5b.png)

Courtesy of Pixabay

在我们为机器人起义做准备之前，我们必须首先了解人类是如何掌权的。

计算机将发展认知和分析独立性的假设，以及这种独立性将不可避免地导致它们暴力地摆脱血肉压迫者的枷锁，既是许多反乌托邦小说的素材，也是大多数人工智能末日场景的关键。然而，围绕自我意识机器的狂热缺乏对意识及其对拥有它的主体的影响的基本理解。为了更清楚地思考人工意识，我们必须考察两个问题:我们对人类意识了解多少？我们能把自己的意识应用到机器上吗？

# **什么是意识？**

意识，即使适用于我们自己，也是我们还没有就定义达成广泛共识的东西——甚至可能还没有完全掌握。因此，为了定义意识的开端是什么样子，几乎不可能在一系列必要条件上达成一致。

最广义的[中的意识](https://www.google.com/search?q=consciousness)指的是医学上对有意识和无意识的区分，也就是说清醒并且能够与周围环境互动。然而，这一定义适用于许多不会引起对人类反抗的恐惧的生命体。

为了我们的目的，我们将使用术语“意识”，或多或少与术语“自我意识”互换，以包括对存在的理解和主观意识；换句话说，意识到自己是一个与周围环境截然不同的独立实体，拥有独特的个人经历，并有可能对周围的世界产生影响。

为了尽可能简洁，我们还将关注人类意识——动物意识是另一天的另一个冗长的争论，再次回到对分类或决定谁合格或不合格的要求缺乏共识。无论如何，我们还不能确定大脑中到底发生了什么，或者在哪里产生了意识。

# 人类是在什么时候获得意识的？

意识不确定性的一个方面是决定我们何时发展出这个我们不能轻易定义的东西。除此之外，如果我们能够决定需要什么样的物理证据来检查我们尚未建立的众所周知的盒子(然后我们开始……)，那么就需要有根据的猜测来对文字出现之前发生的任何事件得出结论，并将其应用于可能没有留下任何物理证据的事情。例如，很容易假设洞穴艺术是意识的标志，但是人类在获得意识后多久才开始绘画？

一种更具经验性的方法可能是关注人类及其祖先的身体变化，这些变化可以通过化石记录进行追踪，并将我们与其他(表面上没有自我意识的)动物王国区分开来——即发展出一个巨大、复杂而强大的大脑。人类学家已经确定了生活方式的改变，他们认为这是在 200 万到 300 万年前发生的——通过吃肉增加我们的蛋白质摄入量，这反过来通过制作石器和用火烹饪成为可能。

意识允许早期人类在精神上把自己从眼前的处境中分离出来，大胆思考，想出能让他们生活得更好的解决方案。这是让我们成为这个星球上优势物种的因素之一(或者可能是*T3 因素，如果我们仅举一个例子的话)。*

假设是，如果我们可以确定人类何时以及如何获得意识，我们就可以控制(或者至少预测)机器是否或者何时会做同样的事情。

# **人工智能将在什么时候获得意识，如果有的话？**

首先，也是最重要的，不是在最近的将来；专家们仍然在谈论几十年后有自我意识的人工智能的出现。在机器能够开始跳出预编程的框框思考之前，它们还有很长的路要走。尽管计算机看起来无所不能，但它们并不全面，而是在特定的任务中表现出色。例如，[机器学习算法现在可以创建其他机器学习算法](https://thenextweb.com/artificial-intelligence/2017/10/16/googles-ai-can-create-better-machine-learning-code-than-the-researchers-who-made-it/)(当它们被编程为这样做时)，但这仍然只是在执行它被分配的任务。机器在从单纯的智能飞跃到意识之前，需要进行大量的独立研究。即便如此，在意识达到之后，机器似乎也不太可能立即发展出“附件”(以及同样抽象的概念)，比如创造力和自由意志。

# **接下来会发生什么？**

当考虑到机器已经控制了个人数据、社交媒体和智能设备(仅举我们日常互动的例子)等事物时，人工意识的影响是巨大的。)然而，关于人工意识之后会发生任何负面事情的猜测，是建立在一系列假设和心理技巧之上的，比如:

1) **机器人叛乱的存在假设先前的集结是不可预见和/或不可阻挡的**；否则，我们怎么可能让它发生呢？计算机有记录它们所做的一切的寄存器，可以防止它们隐藏它们执行的任何进程。由于这个原因，很难想象一个真实世界的场景，人类会被突然袭击和/或无法做任何事情来阻止他们迫在眉睫的厄运(比如说，拔掉插头)。)

2) **对意识机器即将造反的恐惧假设意识的唯一(或最有可能的)产物是造反**。这在本质上与假设任何人都会因为拥有意识而反抗社会是一样的。根据经验，我们知道情况并非如此；一些人觉得现代文明的条件难以忍受，而另一些人却对此感到非常舒服。我们可以推断出这种现象，并相当肯定地预测有意识的机器在态度上会有同样的分歧。第四点对此有更多的介绍。

3) **我们正在人性化机器！对有意识机器的天生恐惧假设有意识机器也会发展人类的黑暗倾向——这可以说只是我们动物过去的遗留物。不合逻辑的偏执、暴力反应和对任何不受我们控制的事物的恐惧在野外足够普遍，因为它们对在那种环境中生存很有用，但同样的逻辑表明，这些倾向不会不可避免地发生在没有经过相同进化过程的机器中。这些趋势需要被明确编程，或者通过[偏差](https://www.technologyreview.com/s/608986/forget-killer-robotsbias-is-the-real-ai-danger/)发生。在这种情况下，我们将与一台或多或少为邪恶而故意制造的机器打交道，这与一台有自我意识的机器独立做出邪恶的决定不是一回事，无论如何，一台足够先进的机器可能能够识别并克服其创造者的偏见。**

4)**与此同时，当我们假设所有的人为意识都会攻击我们时，我们就是均质化机器**。重要的是要注意到(对个人的启迪和对人工智能的应用)意识不是每个人都以同样的方式体验的，主观性的一部分是它与客观性完全相反；一些哲学家和心理学家将这种现象称为[特质](https://plato.stanford.edu/entries/qualia/)。由此我们得出不同的人有效地生活在不同的现实中。显而易见，如果人类意识因人而异，那么人工意识也会因机器而异。在一个机器起义的事件中，其他不同意的机器也会来帮助我们。

人工意识的半满玻璃愿景谈到了从人工智能到[增强智能](https://bdtechtalks.com/2017/12/04/what-is-the-difference-between-ai-and-augmented-intelligence/)(对人类而言)的过渡，增强智能更具协作性，专注于相互改进，以更好更快地执行任务。在这种情况下，或许更有效、更直接的担忧是技术发展的委婉说法“颠覆”，以及我们将如何适应生活在一个大部分传统人类工作可以由机器完成的世界。在这个场景中，我们更加确定地知道[将会发生什么，以及什么时候发生。](https://www.weforum.org/press/2018/01/reskilling-revolution-needed-for-the-millions-of-jobs-at-risk-due-to-technological-disruption/)