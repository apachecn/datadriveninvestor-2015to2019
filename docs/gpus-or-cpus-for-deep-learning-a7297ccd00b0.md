# 深度学习用 GPU 还是 CPU？

> 原文：<https://medium.datadriveninvestor.com/gpus-or-cpus-for-deep-learning-a7297ccd00b0?source=collection_archive---------17----------------------->

![](img/2c022b86a7f1f5b02863293e2ed75e54.png)

[Photo](https://www.pexels.com/photo/blur-close-up-computer-device-343239/) by [Jordan Harrison](https://www.pexels.com/@jord) from [Pexels](https://www.pexels.com)

GPU 对神经网络计算的重新调整和扩展彻底改变了深度神经网络架构的可能性，并使大型通用模型(如 Inception 和 RestNet)在计算上变得可行。这是为什么呢？是什么让 GPU 比 CPU 更适合这些计算呢？

当亲自解释这一点时，我发现考虑与 3D 渲染的相似性是最有帮助的。有些人可能已经知道，任何 3D 模型都是由镶嵌(或小三角形)组成的，这些镶嵌都是使用适当的材质、闪电、位置及其其他属性渲染的。换句话说，必须对每个镶嵌的**执行完全相同类型的计算。同样，相同的微分损失函数必须通过神经网络反向传播——针对每个神经元**。因此，以这种类似的方式，单个(分组)操作必须在一大组神经元上执行，就像它必须在镶嵌上执行一样。****

**虽然到目前为止这似乎是有意义的，但是 GPU 的哪些属性使它更擅长在许多数据点上执行相同的操作呢？答案在于 GPU 可以做出而 CPU 不能做出的硬件权衡。虽然现代 CPU 有很多硬件专用于提取和解码操作的经典阶段，但 GPU 有一小部分硬件专注于理解实际执行的计算。由于 GPU 的主要区别是在不同的数据点上执行相同的操作，所以更多的内核，更具体地说是 alu(算术逻辑单元)可以被打包到同一个芯片中。这就是为什么 GPU 的内核数量往往比 CPU 多几个数量级的原因。一方面，CPU 可以通过使用乱序执行或推测执行等技巧来优化一般操作性能，GPU 完全不需要这种硬件。**

**换句话说，GPU 和 CPU 有不同的用途。在 CPU 上执行图形任务或在 GPU 上进行通用计算将导致极其糟糕的性能。诀窍在于知道何时使用哪一个。**