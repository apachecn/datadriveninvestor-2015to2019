# 另一个人工智能预测

> 原文：<https://medium.datadriveninvestor.com/another-ai-prediction-piece-45f36e6398a?source=collection_archive---------16----------------------->

![](img/1d7c3524c8f1c2c8ef96f8055ca16454.png)

我想用一个简单的游戏开始这篇文章。如果你愿意，请猜猜两个不同的预测是在哪一年做出的，不要用谷歌搜索。第一个预测来自 H.A. Simon，他写道“在 20 年内，机器将能够做任何人能做的工作”。雷·库兹韦尔说得更具体，他声称到 2029 年将会开发出和人类一样聪明的计算机。在 2018 年相信这些预测并不需要多大的信仰飞跃。计算机可以在国际象棋、围棋以及我们能设计的任何其他策略游戏中击败人类。他们比最好的医生更擅长识别疾病，能够很好地使用语言来愚弄人类的对话伙伴，并有可能使人类像马一样与交通工具无关。

你猜猜看？那些不精通人工智能研究历史的人可能会惊讶地发现，第一个预言来自 1965 年，第二个来自 1999 年。对于现代数据科学家来说，H.A. Simon 如此信任的人工智能几乎是不可识别的。当时，人工智能是基于大规模的语义网络，明确表明对象和概念之间的关系。想象一下，列出你所知道的关于椅子的所有东西，然后把这个列表和与椅子相关的所有其他概念联系起来，每个概念都有自己相应的列表。

时间证明了这种方法的批评者是正确的，几十年来几乎没有进展的努力和一些人工智能“冬天”已经证明了这种僵化范式的缺点及其支持者的过度自信。激发库兹韦尔信念的现代人工智能是基于非常不同的原则，这使得他的乐观主义的有效性不太清楚。毕竟，自然选择进化的昏昏欲睡的随机性已经产生了一个真正的智慧，什么能阻止科学的快速、结构化的研究产生另一个呢？

令人欣慰的是，这种可怕的生存威胁可能比 2029 年更遥远。虽然现代人工智能能够完成一些令人印象深刻的壮举，例如在某些癌症的识别方面胜过临床医生，但它仍然是狭隘的和特定的问题。现代的下棋计算机远胜于任何人类，但没有能力回答对话问题。相反，即使是最令人信服的聊天机器人也会是一个完全迟钝的棋手，试图向这样一个程序解释国际象棋的规则是完全徒劳的。

这似乎只是一个小小的绊脚石。可以肯定的是，鉴于进步的速度，DeepBlue 和 AlphaGo 将很快取代 Alexa 和 Siri。然而，这种限制对现代人工智能来说更为根本。现代人工智能的中心范式是成本函数的最小化。虽然这在实践中极其技术化和复杂，但概念本身非常简单(魔鬼总是在细节中)。当呈现一些输入时，比如一张照片或一些文本，人工智能程序将有许多(可能是无限的)潜在输出，或可用的响应。每个输出都有一个与之相关的数字或分数，程序只选择最小(或最大)的输出。与每个响应相关联的数字是使用先前输入-输出组合的大型数据库生成的。

现代人工智能的力量来自这个框架的多功能性。这个过程的每一步都可以用多种方法解决，这使得现代人工智能成为一个非常有用的工具。不幸的是，这也是限制现代人工智能的原因。虽然游戏、物体识别和疾病识别等任务可以很容易地适应这个框架，但不清楚如何生成这样一个独立于上下文的成本函数或分数集。尽管我们有缺陷，但人类似乎拥有这种独立于环境的智能。像智商这样的测量方法就是试图测量这个量。这种与上下文无关的成本函数的缺乏成为使用现代方法的一般人工智能的基本障碍。

这样的阻碍并没有阻止人工智能在广泛问题上的应用。世界上最有价值的公司之一 Alphabet 将其核心商业模式建立在人工智能的应用上。Alphabet 已经彻底改变了广告和我们与信息的互动，并正在调查令人眼花缭乱的更多不同领域。以其自动驾驶汽车子公司 Waymo 和 Project Maven 为例，在内部审查结束该项目之前，谷歌与五角大楼合作开发了军用无人机照片的自动图像处理。

然而，关于人工智能军事化的争议并不是从 Project Maven 开始的。2017 年，116 名技术领袖签署了一封信，呼吁联合国禁止“杀手机器人”，即带有致命意图的自动化设备。如果把终结者想象成这种发展的最终结果，这样的要求似乎是合理的，但是自动致命平台有一些明显的好处。不像真正的士兵，他们永远不会疲劳，滥用权力，或者身体上，或者更经常地精神上，崩溃地回家。战争是地狱，如果我们不那么不切实际地呼吁结束战争，我们又有什么资格将无数未来的士兵交付给战场的恐怖和它所带来的令人衰弱的伤害呢？鉴于签署这份文件的科技领袖们与战争的恐怖完全隔绝，这样的批评尤其贴切。更不用说与核装置的力量相比，这种机器是微不足道的，核装置对人类构成的生存威胁比编程杀人的机器人大得多，并且已经存在数千个。

另一个严重的担忧是经济中断，因为现代人工智能有可能使当今存在的许多工作自动化。Nedelkoska 和 Quintini 最近的一份报告将整个经合组织的这一数字定为 14%,其中 32%的人可能在所需的必要技能方面经历“重大变化”。这种变化不会马上发生，但仍有可能相当迅速地发生，或许在未来十年内。这是一个令人担忧的趋势。根据国际货币基金组织的一份报告，过去三十年来，取代大多数文书和通信工作的自动化浪潮是劳动力收入份额下降的大约一半原因。许多人将这一趋势归因于西方经济民粹主义的兴起和政治不稳定。

尽管所有这些都令人担忧，但没有一个是世界末日。值得注意的是，与工业革命带来的组织变革相比，这些现代变革相形见绌。正如马丁·沃尔夫在他为《外交事务》撰写的文章《一如既往》中所写的那样，我们“对我们这个时代微不足道的创新印象深刻”，因为我们“认为过去的创新是理所当然的”。电灯、自来水、汽车和电话等进步对人们工作、生活和交流方式的革命性远远超过过去三十年人工智能研究的任何发展。现代发展更好地被描述为这些发明所建立的系统的改进，而不是剧烈的范式转变。同样，原子弹的发展不可逆转地改变了战争和冲突的性质。

这并不是说人工智能带来的变化不会导致社会变革，而是应该激发人们的信心，相信更具革命性的变化已经在经济和社会方面得到了安全的管理。我们不应该仅仅因为有风险就停止发展，从而限制自己。风险是未来固有的，人工智能带来的风险并不比没有它的世界更大。

事实上，现代人工智能是有效处理当代社会复杂性的强大工具。苏黎世联邦理工学院的研究人员正在研究通过自动化气流和温度管理来使用人工智能提高建筑效率和舒适度。无人驾驶汽车有可能通过更有效的车对车通信来大幅减少道路死亡和拥堵。人工智能最近在农业中的应用通过识别和管理土壤和作物条件提高了作物产量。任何有复杂系统被用于特定任务的地方，人工智能都有巨大的潜力使用超人的管理和协调技能找到最佳解决方案。随着越来越多的人搬到城市，协调和管理资源的问题只会变得越来越困难。我们必须提高水分配、食品生产和能源管理等任务的效率，而现代人工智能恰恰承诺了这样的改进。更何况这已经开始了。考虑使用人工智能将谷歌数据中心的能源使用减少 15%。随着我们经历伴随全球变暖的大规模生态和环境变化，现代人工智能可能不是我们有资格辩论的工具，而是可能成为人类持续繁荣的必要组成部分，尽管它有内在的局限性。

这是现代人工智能的谦逊承诺。当人们超越其被极大夸大的风险和利益时，它代表的不是革命性的飞跃或不可救药的错误，而是人类可以用来更好地塑造未来的一套新工具。它在复杂系统的管理中显示出了希望，这种能力表明了它在管理我们组织自己的日益复杂的方式中的效用。它开启了发现新效率的可能性。简而言之，它为我们提供了更好地做我们所做的事情的能力。

但是，也许这一预测在 50 年后会显得愚蠢。我在本文开头故意在游戏中误导你，原因不是廉价扭曲。旧预测的现代性凸显出，尽管方法、工具和情况会发生变化，但人类的乐观和傲慢是永恒不变的。当我们满怀诗意地憧憬我们最喜爱的新玩具的未来时，我们明智地记住了这一点。