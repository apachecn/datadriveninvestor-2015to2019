# 泛智能共存——谁是智能的(2/3)

> 原文：<https://medium.datadriveninvestor.com/pan-intelligence-value-of-live-2-3-1c0c5955eac6?source=collection_archive---------9----------------------->

[![](img/9def793ff809ba40dec5fc2702433ad9.png)](http://www.track.datadriveninvestor.com/1B9E)![](img/a92b93bb6f0d45f5ff6ede572525bf09.png)

Photo by [Ricardo Rocha](https://unsplash.com/@rcrazy?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

这是讨论跨智能物种共存的三集迷你系列的第二集。第一个可以在这个链接找到:[https://medium . com/datadriveninvestor/pan-intelligence-value-1-3-c 946 ebad 8535](https://medium.com/datadriveninvestor/pan-intelligence-value-1-3-c946ebad8535)

*这个话题的重要性源于我们在两个方面的持续努力:SETI(寻找外星智能)和人工智能。任何一方取得重大进展都将导致一场不可避免的谈判，即泛智关系应该如何发展，以及什么将成为相互信任和互利关系的基础。*

我们能否让其他形式的智慧相信我们的幸福是有价值的，我们是否应该尊重他们的幸福？谁被认为是聪明的？

在第一部分中，我考察了一个最低限度令人满意的人类价值概念，因此我们个人在这个概念上的分歧不太可能损害我们在跨智能物种共存中的集体机会。提出的价值概念是，“**一个人帮助他人增加福祉的程度**”。

[](https://www.datadriveninvestor.com/2019/03/01/the-myth-of-ais-predictive-power/) [## 人工智能预测能力的神话——数据驱动的投资者

### AI(人工智能)最有前途的优势之一似乎是它预测未来的能力…

www.datadriveninvestor.com](https://www.datadriveninvestor.com/2019/03/01/the-myth-of-ais-predictive-power/) 

这有助于阐明人类是一个集体单位，有着共同的兴趣、目标和体验“存在”的“理由”。然而，我们在第一部分中使用了“人类”，这根本不是“跨智能物种”。

为了允许泛智能协商，我们需要允许将术语“人类”扩展到一组新的“主体”(或智能代理)，这个过程有两个基本含义:

1.  当我们讨论幸福时，谁(或什么)将被包括在集合中？一个屠夫肯定对人类社会的肉食饥饿成员的福祉有所贡献，然而，如果我们将牛纳入“福祉”的计算，屠夫的价值将成为一个有争议的命题。因此，我们似乎认为人类(以及我们的一些食肉宠物)包括在“幸福”的计算中，而奶牛则没有(至少不平等，而且“折扣”很大)。但是一种智能生命形式呢，无论是外星人还是人造生命？
2.  作为第一点的延伸，一旦我们决定了谁被包括在内，那么一个代理人增加了一些人的福祉，却伤害了一些人呢？一个极端的例子是阿道夫·希特勒，他给数百万人造成了难以想象的伤害，同时可以说，至少他的一些亲密圈子从他的存在中受益。不应该围绕这样一个结论有太多的争论:如果他不曾存在过，世界的整体福祉就会增加(他有净负值)。但并不是所有的情况都那么极端，一个更常见的困境是众所周知的[电车](https://www.youtube.com/watch?v=bOpf6KcWYyw)思维实验——它在许多测试中被重复，随着潜在受害者的数量增加，更多的人倾向于扳动开关，让电车进入侧轨，杀死单个工人。然而，即使对于极端动物权利活动家来说，如果一条轨道上是 1 个人，而另一条轨道上是 5 头、50 头甚至 500 头牛，这可能也不是一个具有挑战性的问题。

**展望未来，我们是否准备好说服另一种形式的智能把我们当作伙伴，而不是食物？**

如果是 1 个外星人对 5 个人类呢？如果是单个 AI 控制整个世界 vs. 50 个人类呢？如果单个人工智能的消亡会导致世界末日呢？

从屠夫的例子中我们知道，拥有生存本能不足以让我们将奶牛纳入我们的福祉讨论，至少不能作为完整的单位。

这场争论已经持续了几千年，佛教和印度教认为所有动物(有些人甚至认为所有生物包括植物)都是福祉关注的合理对象，因为它们感觉疼痛，并表现出生存本能(正统的佛教徒比素食者更进一步，他们只吃别人的剩饭，以尽量减少对所有生物包括植物的暴力)。

但是大多数“人类”的“幸福”已经超过了动物的幸福。(这是一个比动物权利更大的问题，即使在今天，在一些司法管辖区，妇女仍然没有“充分”的权利，在福利问题上受到忽视。)

因此，我们自己的生存欲望，不管我们如何强调它，很可能都不足以说服另一种智慧形式尊重我们的福祉。

实际上，(除了特定情况下的少数例外)没有强有力的进化理由让另一个物种尊重(或负责)另一个物种的个体福祉。我们不必处理这一发现的后果，仅仅是因为自有文字记载的历史以来，我们一直处于食物链的顶端，这意味着我们比其他物种更不容易遭受这一“问题”。

从*人工智能*的角度来看，这个问题在媒体开始担心“你的自动驾驶汽车应该杀死谁，你还是旁观者”的几十年前就已经是一个迷人的话题了。

在电脑和奶牛之间，大多数人(包括我)在“生死攸关”的情况下会毫不犹豫地选择奶牛。但是一头牛不会计算 7+9=16，而一台计算机会，而且实际上可以做微积分，线性代数，以及牛不会的各种数学。

一台电脑甚至可以打败最好的国际象棋选手和最好的围棋选手。你应该“杀死”一头牛，或者一只能打败最好的围棋手(可以说是人类有史以来发明的最复杂的硬规则游戏)的牛吗？

这个难题的一部分可以通过外部化我们对此的判断来尝试——如果我们可以编程我们的 AI 在没有人类干预的情况下做出这种判断，我们就大大增加了说服其他形式的智能(无论是超级智能还是智能外星人)至少考虑我们的建议的机会——毕竟，判断可以在我们自己的思想之外做出。

然而，大多数哲学观点不够客观，无法被以算术为中心的机器处理，而这些机器可能需要在不久的将来做出判断。

让我们想象一下，我们正在试图确定一个外星生命形式是否有智慧，我们使用的标准是什么？比起硅形态，我们更喜欢外星人的肉体形态吗？

或者，反过来，一个外星超级智能拜访地球，谁更有机会向超级智能传达“我很聪明”的信息？一台电脑，一头牛，还是一个人？

毫无疑问，早期的尝试之一是由独一无二的艾伦·图灵提出的——[图灵测试](https://en.wikipedia.org/wiki/Turing_test)(或者现在更为人所知的模仿游戏)是一个关于“谁/什么被认为*和*一样聪明”的大讨论。

这个想法很简单但很强大——与其确定思想的起源和机制，不如通过可观察的表现来判断——如果机器可以像人类欺骗者一样成功地愚弄人类法官(就频率而言)，那么机器是否拥有我们所理解的智能“重要”吗？我们能说机器可以表现出与人类一样的智力吗？

将图灵测试和电车问题结合起来是相当可怕的，假设你是法官，你负责一个控制唯一剩余电力供应的开关——它可以用来为人类的氧气发生器供电，或为计算机供电，但不能同时为两者供电。就像标准的图灵测试一样，在两扇门后，一个密封的房间里是一个人，另一个是一台计算机，你的工作是通过文本终端找出哪个是人，然后按动开关，延长你认为需要保存的人的“生命”。

还不需要因为这个测试而失眠，目前，我们还没有一台可以持续通过图灵测试的计算机(图灵的标准是计算机是否可以在愚弄法官方面达到类似的成功率，这意味着它是许多轮游戏的统计结果，而不是一轮测试，这使得它比大多数人第一次出现时更难)。

许多专家，包括人工智能圈内的一些人，批评图灵测试没有检查智能的本质、机制或来源。虽然科学家们非常渴望研究这些思想的机制和起源，并设计标准来衡量人工智能研究工作的广度，但这对图灵测试来说是一个错位的负担——特别是在判断我们所知甚少的其他形式的智能时，例如，一种外星智能可能来自完全超出我们理解能力的机制。试图根据他们与我们的相似程度来判断他们可能是一个危险的命题——特别是如果他们比我们先进，无论是外星人形式还是人工超级智能形式——他们可能也在试图判断我们！

现在想象一下，在我们之前的标准图灵测试中，一个外星人将扮演法官。外星人不知道谁是“活着的”，是人类还是计算机，对人类语言只有简单的了解(他们在技术上很先进，所以解码了人类的一些语言)，但它也依赖于人类测试对象(和计算机)学习一点点他们的语言，以便更好地与他们交流。现在，与机器相比，人类测试对象获得能量的机会有多大？

当法官不认同我们自己的身份和谈话中独特的内在感受时，就很难说服他们谁是“聪明的、有生命的”。

在我的另一篇文章中，[当我们将我们的智力外化以创造人工智能时，它也改变了我们对人类智力的想法](https://medium.com/design-and-tech-co/while-we-externalize-our-intellect-to-create-ai-it-is-also-changing-our-idea-of-human-intellect-1a07d22caa8f)，我讨论了我们倾向于忽视我们理解其机制并能够在大脑之外复制的智力。然而，如果一个超级智能实际上知道我们大脑如何工作的机制，甚至能够控制我们的思想，他们会把我们当作“已知的主观感觉机制”而不予理会吗

一个(某些)通用信息处理规则的客观抽象，恐怕是与其他智能形式交流的一个很好的表征。数学和逻辑似乎是很好的候选对象，这些信息结构似乎存在于我们的大脑之外，任何具有正常认知能力的人都能够以可预测的结果执行大多数这种信息处理——并且很有可能其他形式的智能也能够以同样的方式执行数学和逻辑运算。至少对于 AI 来说，这是已知的事实。

另一个障碍是我们需要区分进化和智能行为。

这不是新闻，我们很久以前就知道进化可以像一种“优化”算法——淘汰不适合者的机制基本上是一种树搜索算法(虽然最终结果是在成功的解决方案端出现一个生物，但这一过程取决于大多数人的尝试和消亡的“牺牲”)。

考虑到所有这些，我们的标准的一个好的起点将是*一组可以观察到的相互支持的个体，集体能够以可预测和可再现的结果执行逻辑信息处理，并且能够外化这种能力。*

客观性对于确保跨情报交流所需的可重复性和可预测性非常重要。(纯粹的主观感觉很难与动物的生存本能区分开来，后者更多的是“活着”的特征，而不是“有智慧”的特征)

我们的主观性可以表现为对他人幸福的关心，这是超越个体生存的更高层次的关心。我们以这种方式行事的能力，以及将我们对福祉的关心扩展到其他智能形式的意愿，将大大有助于转换这样一种信息，即我们是智能物种家族中一个卑微的成员——我们是目前唯一知道的一个，但我们正在 SETI 和 AI 方面努力工作，以“减轻作为唯一智能形式的孤独感”。

P.S .说到动物的生存本能，尽管我们想拒绝鹦鹉只是“模仿我们的声音”，但我们证明它们实际上不理解它们发出的声音的“证据”还不是很有说服力(换句话说，我们实际上还没有聪明到可以断定鸟类不聪明！).

谢天谢地，到目前为止我们还没有看到鹦鹉数到 7 以上——我们不确定大自然是否会保持这种状态。然而，我们知道乌鸦实际上可以用小树枝制作工具，并用石头来提高水位以获取食物。如果我们应该把乌鸦当成不会说话的鸟，这确实是有问题的，因为执行它们的一些活动所需要的计划水平是相当高的。但我们可能会冒险声称，乌鸦制造工具并没有将信息处理能力具体化——因为它没有执行我们可以客观复制的逻辑或数学运算。