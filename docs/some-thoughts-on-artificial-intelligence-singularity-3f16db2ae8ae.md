# 关于人工智能奇点的一些思考

> 原文：<https://medium.datadriveninvestor.com/some-thoughts-on-artificial-intelligence-singularity-3f16db2ae8ae?source=collection_archive---------3----------------------->

奇点是一个数学术语，用在许多不同的上下文中。在技术领域，特别是在人工智能领域，这个术语具有深远的哲学、社会和技术影响，将塑造人类的未来和技术进步的方向。

奇点将标志着人工智能变得比人类更聪明的时刻。正如维基百科所定义的:

> 技术奇点(或奇点)是一种假设，即人工超级智能(ASI)的发明将突然引发失控的技术增长，导致人类文明发生深不可测的变化。根据这一假设，可升级的智能主体(如运行基于软件的人工通用智能的计算机)将进入自我改善周期的“失控反应”，每一代新的更智能的主体出现得越来越快，导致智能爆炸，并产生强大的超级智能，在质量上远远超过所有人类智能。

随着类似 [*生成对抗网络*](https://en.wikipedia.org/wiki/Generative_adversarial_network) 这样的技术的出现， [AI 天启](https://en.wikipedia.org/wiki/AI_takeover)这样的可能性似乎也不是不可能。当许多新兴的颠覆性技术(如量子计算、AR/VR、区块链、3D/4D 打印合奏)以人类思维尚未想到的方式工作时，这个问题变得更加复杂。

关于这个问题的想法对我来说并不新鲜。大约 22 年前，当我第一次看电影《终结者》时，我被时间旅行的想法迷住了，以及人类如何可能从由于机器的崛起而导致的存在终结的可能性中拯救自己。这样的人类思想可以追溯到工业革命时期，当时机器或自动机被比作火神，一个与儿童献祭有关的古代迦南神。像艾伦·图灵这样的计算机科学大师表达了他们对这个问题的担忧。最近，史蒂芬·霍金的新书《大问题简要回答[](https://www.amazon.in/Brief-Answers-Questions-Stephen-Hawking/dp/1473695988)*的出版再次提出了这个话题。正如 [Vox](https://www.vox.com/future-perfect/2018/10/16/17978596/stephen-hawking-ai-climate-change-robots-future-universe-earth) 所说，*

> *霍金最大的警告是关于人工智能的崛起:它要么是发生在我们身上最好的事情，要么是最糟糕的事情。如果我们不小心，这很可能是最后一件事*

*当我重温这个话题时，我发现这两个令人印象深刻的观点被发表在[麻省理工科技评论](https://www.technologyreview.com)上的该领域的专家所分享:*

# *[不，专家们不认为超智能人工智能对人类构成威胁](https://www.technologyreview.com/s/602410/no-the-experts-dont-think-superintelligent-ai-is-a-threat-to-humanity/)*

# *[是的，我们担心人工智能的生存风险](https://www.technologyreview.com/s/602776/yes-we-are-worried-about-the-existential-risk-of-artificial-intelligence/)*

*前一篇文章是柳文欢·埃齐奥尼教授的观点，他是艾伦人工智能研究所的首席执行官，也是华盛顿大学的计算机科学教授。后一篇文章由耶鲁大学政治学助理教授艾伦·达福和加州大学伯克利分校计算机科学教授斯图尔特·拉塞尔撰写。*

*在背景下，他们讨论了尼克·博斯特罗姆教授的工作，他是牛津大学的瑞典哲学家，也是哲学论文 [*超级智能:路径、危险和策略*](https://www.amazon.in/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0198739834/ref=sr_1_1?s=books&ie=UTF8&qid=1539842483&sr=1-1&keywords=superintelligence) 的作者。*

*专家们在这个问题上的观点和信念可以总结如下:在不远的将来(即未来 30-70 年)，人工智能可能不会出现威胁我们生存的惊人崛起，但长期观点应该认识到 [AGI](https://en.wikipedia.org/wiki/Artificial_general_intelligence) 对人类构成[生存威胁](https://nypost.com/2017/12/28/terrifying-stories-that-prove-the-ai-apocalypse-is-imminent/)的可能性，并应该要求我们努力实现[负责任的人工智能](https://ai.google/education/responsible-ai-practices)未来。*

*# AI #机器学习#奇点#超智能#ASI*

*(这篇文章的缩小版出现在我的 linkedin 个人资料上)*