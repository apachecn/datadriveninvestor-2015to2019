# PAC-Learnable，工作和阴谋的未来

> 原文：<https://medium.datadriveninvestor.com/pac-learnable-the-future-of-work-and-conspiracy-3c17e3e6a4a1?source=collection_archive---------16----------------------->

[![](img/1e7bec8becfff8256dd1dbcd356172a8.png)](http://www.track.datadriveninvestor.com/1B9E)

在过去的几天里，我一直在忙着重读 LeCun 等人的 [*一篇关于基于能量的方法的教程*](http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf) ，以最终确定我的可解释性框架。最后，我设法解开了 ReLU 单元和层的基于参数的微分算子，所以从这里开始应该是一帆风顺的。

此外，来自《未来之罪》的迈克尔·k·斯潘塞同志写了一篇关于*未来工作的超级有趣的[帖子](https://medium.com/utopiapress/this-is-the-future-of-work-b0b05ac33baf)。斯潘塞认为自动化会威胁到美国现有的 25%的技术工作，以及高达 50%的非技术工作。此外，(我引用):*有一种精英叙事*淡化了这种风险。这让我想起了很多托尼·内格里的*帝国……**

我不仅想知道工作替换，也想知道薪水。如果人工智能将为我们做繁重的工作，我们的工资应该更低吗？如果斯潘塞的话是预言，世界将会变得更加黑暗。第一个令人沮丧的是人工智能驱动的失业，第二个是人工智能驱动的混乱，这是我写这篇文章的灵感来源。

令我们难以置信的是，从电脑上获得的回答从来都不是绝对的。除了编程时的编译错误，应用程序和独立程序中的技术故障属于软件片段中的一类*逻辑错误*(有些可以通过一个很好的老式 *Ctrl+Alt+Del* 解决)。它们要微妙得多，有时几年都不会被发现。

正确性证明和算法验证就像紧身胸衣一样过时了，并且在今天有着几乎相同的目的:只是作为一种迷恋。如今，在经过一系列测试后，系统就像产品(汽车、药品、食品等)一样投入市场*。从用户那里收集反馈是维护和版本控制不可或缺的一部分。现在用户都成了测试者。*

让我们转向 AI mayhem，回忆皮克斯的*瓦力。瓦力*在一系列冒险之后，发现自己在一家机器人修理店，在那里他遇到了一些超级可爱的*不适合的*机器人朋友。当瓦力寻找夏娃时，他们挣脱束缚，在飞船上肆虐，许多胖子漂浮在周围，不知道飞船的指挥人工智能决定忽略它的主要任务。

在《瓦力》中，不合群的机器人被关在围栏里(对*精神病院的可爱描绘)*。对*来说幸运的是，一切都朝着最好的方向发展:他找到了夏娃，飞船的指挥人工智能被关闭，每个人都回到地球去种一只鞋。其他科幻电影，如 2001 年的《T6》、《T8》、《终结者》、《T9》或《机器人》( T11)告诉我们，远程人工智能不是开玩笑的。*

如果我们认真对待这个问题，*人工智能精神病学*可能是未来需求量很大(希望薪酬过高)的职业之一。也许我们最终会看到像*人工智能耳语者*或*超级人工智能版这样令人上瘾的真人秀。*

![](img/801414a93008ca37c3c157b301878999.png)

Jo Frost Supernnany. Courtesy of [Flow Journal](https://www.flowjournal.org/2011/11/mothers-on-the-naughty-step/?print=print).

除了斯潘塞关于工作自动化的预测，我认为有些将成为人工智能增强的(可能是法律规定的)。专家和推荐系统从 20 世纪 90 年代就已经存在，这并不是什么新鲜事。商业智能现在风靡大公司。

在这里，我想提请注意机器学习中的一部经典著作:l . g . Valiant 1984 年的论文，题为[](https://people.mpi-inf.mpg.de/~mehlhorn/SeminarEvolvability/ValiantLearnable.pdf)**可学习的理论。*在里面，Valiant 介绍了一个有点无辜而且(在我看来)*有争议的*缩写: [*大概，大概正确的* (PAC)](https://en.wikipedia.org/wiki/Probably_approximately_correct_learning) 根据成功率(验证准确度)对任务的可学性进行分类，与数据集大小有关。也就是说，如果一个任务是 *PAC-learnable* 的，则系统*可以学习*执行该任务，并为其提供一个*小的*场景子集，并将其概括为在*所有*其他场景中执行良好。*

*鉴于我对自动驾驶(以及一般驾驶)的无知，让我们将驾驶视为一项 PAC-Learnable 任务。汽车的状态可以简化为一个元组:运动方向(向前或向后)、速度、方向盘角度(以度为单位)和踏板踩踏(也许是一个角度)，作为“周围环境”的函数。我们有输出参数(方向、车轮角度和踏板角度)和输入参数(接近传感器和摄像机)。让一些 AI 学习它，并推断这些周围的情况。为什么不呢？如果人类能做到。*

*现在，让我们假设这样的汽车已经被训练。从用户的角度来看，我们将需要以某种方式与这辆自动驾驶汽车进行交流。既然它是智能的，也许我们可以命令它 *floor it* ，因为我们上班要迟到了。*大概*，不会决定*得到全部杰森·斯坦森，*只是大概*(红旗亲爱的读者，红旗)…**

*PAC-Learnable(在自动驾驶的情况下)的好处在于，我们不需要在任何地方的训练中驾驶自动驾驶汽车，当然不是驾驶吕克·贝松的*露西*风格:只是*一点点*，只是一会儿*。这里我们应该害怕的术语是*大概，*如*概率，*如*统计*(我的克星)。什么构成了足够多样的场景样本？**

**也许我的恐惧完全是多余的。包装可学性的问题非常广泛。让我们解决一个具体的问题:分类。在这里，我想提请注意[威尔·科尔森](https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c)[的](https://medium.com/u/e2f299e30cb9?source=post_page-----3c17e3e6a4a1--------------------------------)这篇文章中的一些评论，关于有偏差数据集的修正性能指标，以安抚你亲爱的读者。**

**Koehrsen 通过假/真阳性和阴性来量化人工智能系统中的*偏差*。他指出，在许多情况下，准确性(在培训和验证中)并不是衡量成功的绝对标准。检查这一段:**

> **恐怖分子检测任务是一个**不平衡**分类问题:我们需要识别两类——恐怖分子和非恐怖分子——其中一类代表绝大多数数据点。当疾病在公众中的发病率非常低时，另一个不平衡的分类问题出现在疾病检测中。在这两种情况下，积极阶层——疾病或恐怖分子——在数量上远远超过了消极阶层。这些类型的问题是数据科学中相当常见的情况的示例，此时准确性不是评估模型性能的良好度量。**

**Koehrsen 使用*召回*和*精度*的概念来打破数据集的不平衡，并将结果系统中的*偏差*的问题(在我看来很漂亮)减少到四个变量，即分类器的*混淆矩阵*(喜欢这个术语):假阳性、假阴性、真阴性和真阳性的数量。**

**也许我来这里有点晚了，混乱矩阵从一开始就存在，但作为一个新手和共谋者，我忍不住欣喜若狂。我声称精确和回忆是人工智能精神病学实践中的两个基本要素。**

**此外，我担保公共混淆矩阵，用于那些让我们感觉不好的红绿灯食品标签方案的精神，警告我们最喜欢的垃圾食品中的高糖、钠和脂肪含量。**

**让我们来看看科尔森提出的两个衡量标准:*召回*和*精确*。在分类*的背景下，召回*转化为系统在数据集中找到相关点的能力(相对于真阳性和假阴性)。我斗胆说一句，回忆的同义词就是*坚信* ( *不服输*甚至*偏执* ) *。*虽然*精度*是使用系统正确获取的次数(相对于真阳性和假阳性)来计算的，但更准确的说法应该是*一丝不苟*。**

**因此，高召回率的恐怖分子发现系统将发现每个恐怖分子(同时监禁许多非恐怖分子)，而高精确度的系统将让更多的恐怖分子逃脱，但不会监禁无辜的人。**

**我们想吃什么？有效的发现恐怖分子的系统可以抓住所有的 T21 恐怖分子，还是一个遵守无罪推定的系统？在这种情况下，我们如何构建数据集来满足特定的精度和召回组合？重要的是要注意这两个变量是成反比的。**

**我相信斯潘塞的说法是对的:人工智能会让我们很多人失业。更糟糕的是，在许多领域，我声称我们会很高兴地离开我们的工作岗位。我预测有一天 AI 和人类之间的关系状态会切换到*这很复杂*。**

**对于某些职业，自动化以顾问的形式出现(例如专家系统)。医生可能有人工智能水晶球来帮助他们诊断病人，这不是很好吗？使用推荐系统的更明智的法官还是使用 BI 做出更明智决策的商人？分类就是基于这样的决策。**

**请注意，混淆矩阵作为事后的度量，每个数据集定义了一个系统和一个混淆矩阵。在 PAC-Learnibility 下，不正确的 AI 功能是错误选择数据集的直接结果。纠正是显而易见的:选择另一个数据集，其中一个*可能*会让*近似正确*的奇迹发生。不管是谁问了这样的问题“这个人是恐怖分子吗？”PAC 可以学习吗？也许问题出在问题本身…**

**如果编排系统来回答较小的 PAC-Learnable 问题，而不是根据宽泛的概念，而是根据具体的特征，如攻击性或强奸倾向等，会怎么样？毕竟，许多讨论都将统计数据作为支持*假设的证据。你总是听到一些“事实”,比如 x%的连环杀手是白人男性，女性做类似事情的可能性是男性的两倍，等等。谁说 PAC-Learnable 任务的组成是 PAC-Learnable？***

**这就是我提出一个大红旗的地方:成为一个 PAC-Learnable 是这个任务的固有属性，而不是一个观点。关于分类问题，联合的可能性是无限的。**

**虽然现有系统的信任问题可以用精度和召回来讨论，但是 PAC-leanability 回避了*我们能真正自动化什么*的问题？**

**让我们变得偏执…对计算机有一种乐观的态度。许多人认为它们比人更公正，在获取、处理和整理数据的能力上也更胜一筹。**

**然而，如果在特定领域部署系统的决定落在由公众信念引导的决策者的责任上——在最好的情况下——那么*人民*将迎来自动法官、医生或警察的概率有多大？这就要求在学校和大学里强制推行包装可学理论。**

**最后，我们如何对一个统计上被认为是完美的决定提出上诉？AI 精神病学专家是否也应该服务于法律咨询？我们会在未来期待一季《犯罪心理:流氓人工智能》吗？我看到了特别节目的巨大潜力。**

**再一次，根据精确和召回之间的权衡:决策者(和公众)更喜欢精确还是召回？**

## **来自 DDI 的相关故事:**

**[](https://medium.com/datadriveninvestor/deep-learning-explained-in-7-steps-9ae09471721a) [## 用 7 个步骤解释深度学习

### 和猫一起

medium.com](https://medium.com/datadriveninvestor/deep-learning-explained-in-7-steps-9ae09471721a) [](https://medium.com/datadriveninvestor/which-is-more-promising-data-science-or-software-engineering-7e425e9ec4f4) [## 数据科学和软件工程哪个更有前途？

### 大约一个月前，当我坐在咖啡馆里为一个客户开发网站时，我发现了这个女人…

medium.com](https://medium.com/datadriveninvestor/which-is-more-promising-data-science-or-software-engineering-7e425e9ec4f4)**