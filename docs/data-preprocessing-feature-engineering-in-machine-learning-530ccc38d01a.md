# 机器学习中的数据预处理和特征工程

> 原文：<https://medium.datadriveninvestor.com/data-preprocessing-feature-engineering-in-machine-learning-530ccc38d01a?source=collection_archive---------0----------------------->

![](img/8f9af95c721f9fecb1a0f2518237742b.png)

# 你会学到什么？

*   介绍
*   数据处理——矢量化、标准化和处理缺失值
*   特征工程

# 介绍

在我们深入模型开发之前，我们将如何准备输入数据和目标，然后将它们输入到机器学习模型中。有许多特定于领域的数据处理和特性工程技术，但我将与您分享可以应用于所有数据领域的通用技术。

# 数据预处理

## 什么是数据预处理？

它是将原始数据转化为更有意义的数据或机器学习模型可以理解的数据的技术。真实世界的**数据**通常是不完整的、不一致的和/或缺少某些行为或趋势，并且可能包含许多错误。为了解决这个问题，引入了数据预处理技术。我们将讨论一些数据预处理技术，它们是:

*   …向量化…
*   正常化
*   处理缺失值

## …向量化…

我们给机器学习模型的所有输入值都应该是整数形式的。因为神经网络或通常的机器学习模型处理数据的整数表示。

*   无论我们的数据集是否包含不同类别的类，我们都必须进行一次性编码，将类别值转换为整数表示，这可以由我们的模型来处理。
*   如果它是一幅图像，我们必须把它转换成能被神经网络解释的像素值。我们不能将图像直接发送到神经网络，我们必须将它转换成像素值的数组。

无论你需要处理什么数据——声音、图像或文本，你都必须把它们转换成整数或张量，这就是所谓的数据矢量化。神经网络中的所有输入和目标必须是浮点数据的张量(或者，在特定情况下，是整数的张量)。我们可以使用**一键编码**将分类值转换为整数值。还有很多技术可以用来进行矢量化。

## 正常化

> 归一化意味着将要素转换为相似的比例。

这有助于提高模型的性能和训练稳定性。

例如，在数字分类中，我们的图像数据被编码为 0–255 范围内的整数。在将这些数据输入神经网络之前，我们应该将我们的值标准化，将它们转换为 float32，然后除以 255，这样它们就是 0-1 范围内的浮点值。

[](https://www.datadriveninvestor.com/2019/03/03/editors-pick-5-machine-learning-books/) [## DDI 编辑推荐:5 本让你从新手变成专家的机器学习书籍|数据驱动…

### 机器学习行业的蓬勃发展重新引起了人们对人工智能的兴趣

www.datadriveninvestor.com](https://www.datadriveninvestor.com/2019/03/03/editors-pick-5-machine-learning-books/) 

我们不应将数据输入采用相对较大值(例如，多位整数，比网络权重的初始值大得多)或异质数据(例如，一个特征在 0–1 范围内，另一个特征在 100–200 范围内的数据)的神经网络，因为这将触发较大的梯度更新，并阻止网络收敛。为了使我们的网络学习更容易，您的数据应该具有以下特征:

*   **取小值** -基本上在[0，1]或[-1，1]范围内取大部分值。
*   **同质** -特征应该取大致相同范围内的值。

此外，以下更严格的规范化实践是常见的，可以有所帮助，尽管它并不总是必要的(例如，在数字分类示例中您没有这样做):

*   将每个特征独立归一化，使其平均值为 0
*   独立归一化每个特征，使其标准偏差为 1。

```
x -= x.mean(axis=0)
x /= x.std(axis=0)
```

四种常见的标准化技术可能有用:

*   缩放到一个范围
*   剪报
*   对数标度
*   z 分数

我会在不同的博客中分别写下它们。

## 处理缺失值

有时我们的数据中会有缺失值。

例如，在房价示例中，第一个特征(数据中指数为 0 的列)是人均犯罪率。如果这个特性并不适用于所有的样本呢？这样，训练或测试数据中就会有缺失值。

缺少的值可能是:NaN，空字符串，？，-1，-99，-999 等等。为了理解-1 是否是一个缺失值，我们可以画一个直方图。如果这个变量在 0 和 1 之间具有均匀分布，并且在-1 处有一个小峰，那么-1 实际上是一个缺失值。

丢失的值可以对我们隐藏，并通过隐藏的方式被 NaN 之外的其他值替换。因此，绘制一个**直方图**来识别这些值总是有益的。

一般来说，对于神经网络，输入缺失值为 0 是安全的，条件是 0 还不是有意义的值。网络将从对数据的暴露中得知值 0 意味着丢失数据，并将开始忽略该值。

请注意，如果您预计测试数据中会有缺失值，但网络是在没有任何缺失值的数据上训练的，则网络不会学会忽略缺失值！在这种情况下，您应该人工生成缺少条目的训练样本:多次复制一些训练样本，并丢弃一些您预计很可能在测试数据中缺少的特征。

处理缺失值的方法:

*   *忽略数据行*
*   *回填或前填分别传播下一个或前一个值*
*   *替换为固定值范围-999、-1 等之外的某个常数值*
*   *替换为平均值、中间值*
*   *为空特征*

# 特征工程

> 特征工程意味着将原始数据转换成特征向量

在传统编程中，重点是代码，但在机器学习项目中，重点转移到表示。也就是说，开发人员改进模型的一种方式是添加和改进它的特性。

**特征工程是利用你自己对数据和手头的机器学习算法的了解，通过在数据进入机器学习模型之前对数据应用硬编码转换，使算法更好地工作的过程。**

在许多情况下，期望机器学习模型从任意数据中学习是不好的。我们需要将数据呈现给模型，帮助它更容易地完成模型的工作。

在深度学习之前，特征工程曾经很难或很关键，因为机器学习中的经典浅层算法没有足够丰富的假设空间来自己学习有用的特征。

因此，基本上你必须从你的数据中移除那些与你的预测不相关或对你的预测贡献不大的特征，这有助于你缩小假设空间，使你的模型更容易更快地学习。

例如，在卷积神经网络成功解决 MNIST 数字分类问题之前，解决方案通常基于硬编码的特征，如数字图像中的循环数、图像中每个数字的高度、像素值的直方图等。

但是，现代深度学习消除了对大多数特征工程的需要，因为神经网络能够从原始数据中自动提取有用的特征。

这是否意味着只要你在使用深度神经网络，就不必担心特征工程？不，有两个原因:

*   好的特性将帮助你用更少的计算资源更好更容易地解决问题。
*   好的特性可以帮助你用少得多的数据解决问题。深度学习模型自行学习特征的能力依赖于拥有大量可用的训练数据；如果只有几个样本，那么它们特征中的信息价值就变得至关重要。

机器学习快乐！

想了解神经网络吗？，查看这篇文章:

[](https://medium.com/mlait/getting-started-with-neural-networks-ff506e445f45) [## 神经网络入门

### 深度学习是借助神经网络完成的。它们的工作原理和人脑一样。

medium.com](https://medium.com/mlait/getting-started-with-neural-networks-ff506e445f45) ![](img/c8221aec81165621081f34052666f7a9.png)

## 谢谢大家！

## 敬请关注并与#MLAIT 保持联系

## 关注我们获得更多关于人工智能、人工智能和云的教程，并加入[人工智能协会](https://t.me/mlait)的电报小组