# 使用 Python 中的 ETL 管道的完整数据分析解决方案

> 原文：<https://medium.datadriveninvestor.com/complete-data-analytics-solution-using-etl-pipeline-in-python-edd6580de24b?source=collection_archive---------0----------------------->

[![](img/e51091c154baa19ce494999882233fa0.png)](http://www.track.datadriveninvestor.com/1B9E)![](img/4877d4a0e52c82761e4d0c62b8e5b05b.png)

Photo by [Ahmad Dirini](https://unsplash.com/@ahmadirini?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

> 这篇博客是关于建立一个可配置和可伸缩的 ETL 管道，以解决复杂的数据分析项目。Python 在这个博客中被用来构建完整的数据分析项目的 ETL 管道。

我们都谈论数据分析和数据科学问题，并找到许多不同的解决方案。数据科学和分析已经证明了它在世界上的必要性，我们都知道，没有它，未来就不会向前发展。

但是，当许多开发人员或非开发人员社区试图将他们的数据分析解决方案与整个项目的架构集成时，他们仍然在努力构建一个良好的可配置、可扩展和模块化的代码管道。

[](https://www.datadriveninvestor.com/2019/02/07/8-skills-you-need-to-become-a-data-scientist/) [## 成为数据科学家所需的 8 项技能|数据驱动型投资者

### 数字吓不倒你？没有什么比一张漂亮的 excel 表更令人满意的了？你会说几种语言…

www.datadriveninvestor.com](https://www.datadriveninvestor.com/2019/02/07/8-skills-you-need-to-become-a-data-scientist/) 

在这篇博客中，我将带您经历一系列的步骤，帮助您更好地理解在构建 ETL 管道时，如何为您的数据分析解决方案提供端到端的解决方案。

那么我们先从一个简单的问题开始，即 ***什么是 ETL，它如何帮助我们数据分析解决方案？？？***

问题第一部分的答案很简单，ETL 代表提取、转换和加载。顾名思义，这是一个从一个或多个数据源提取数据，然后根据您的业务需求转换数据，最后将数据加载到数据仓库的过程。要理解数据分析中 ETL 的基础，请参考这篇博客。

[](https://medium.com/p/64346016153d) [## 了解提取、转换和加载(ETL)及其在数据分析世界中的必要性…

### 任何对数据分析感兴趣的人，无论是程序员、业务分析师还是数据库开发人员，都一直在开发 ETL…

medium.com](https://medium.com/p/64346016153d) 

在这篇博客中，我们更感兴趣的是构建一个解决复杂数据分析项目的解决方案，其中需要多个数据源，如 API、数据库或 CSV 或 JSON 文件等，为了处理这么多数据源，我们还需要为 ETL 管道的转换部分编写大量代码。是的，我们还可能需要多个数据加载资源。

因此，根据我的经验，在架构层面上，在构建 ETL 管道时，应该始终牢记以下概念。

> **建筑设计理念**

**可配置性**:顾名思义，就是设计或适应形成一种特定的配置或为了某种特定的目的。但这还不太清楚。你可以把它看作是你代码中的一个额外的 JSON、XML 或名称-值对文件，它包含了关于数据库、API、CSV 文件等的信息。例如，如果我有多个数据源要在代码中使用，最好是创建一个 JSON 文件来跟踪这些数据源的所有属性，而不是在使用它时在代码中一次又一次地硬编码它。*但是这样做有什么好处呢？代码大小的减少*，因为我们不需要在代码中再次提到它。为了将来的灵活性和可维护性，它简化了代码，就像我们需要改变我们的 API 键或数据库主机名，那么它可以相对容易和快速地完成，只需在配置文件中更新它。

**模块化或者松耦合:**这意味着尽可能将你的代码分成独立的组件。例如，假设我们使用 Oracle 数据库进行数据存储。因此，如果我们在代码中为 Oracle 数据库编写一个单独的类，它由 Oracle 连接、数据读取、插入、更新和删除的一般方法组成，那么我们可以在任何使用 Oracle 数据库的项目中使用这个独立的类。这个想法是，单个模块的内部细节应该隐藏在一个公共接口后面，使每个模块更容易理解、测试和重构，而不依赖于其他模块。

**可伸缩性:**这意味着代码架构能够处理新的需求，而不需要对代码基础做太多的改变。在我们的例子中，这是最重要的，因为在 ETL 中，可能有新转换的需求。因此，我们需要以这样一种方式构建我们的代码库，即在未来添加新的代码逻辑或特性是可能的，而无需对当前的代码库进行太多的修改。我们可以在这里利用 OOP 的概念，这也有助于代码模块化。

> **Python 中 ETL 的数据分析示例**

代码的先决条件:

*   Python 基础
*   类别和对象
*   熊猫和熊猫
*   API(请求模块)
*   JSON 和 CSV 文件
*   MongoDB (pymongo 模块)

让我们深入研究管道编码，并弄清楚如何在代码中应用所有这些概念。我将创建一个项目，其中我们使用污染数据，经济数据和加密货币数据。让我们假设我们想要对这些数据集进行一些数据分析，然后将其加载到 MongoDB 数据库中，用于关键的业务决策或其他任何事情。

数据源链接:

API:这些 API 将以 JSON 格式返回数据。

*   污染数据:"https://api.openaq.org/v1/latest？country=IN&limit=10000”。
*   经济数据:" https://API . Data . gov . in/resource/07d 49 df 4-233 f-4898-92 db-e 6855d 4 DD 94 c？API-key = 579 b 464 db 66 EC 23 BDD 000001 CD 3946 e 44 ce 4 aad 7209 ff 7 b 23 AC 571 b & format = JSON & offset = 0 & limit = 100 "

关于加密货币的 CSV 数据:[https://raw . githubusercontent . com/dil Jeet 1994/Python _ Tutorials/master/Projects/Advanced % 20 ETL/Crypto-markets . CSV](https://raw.githubusercontent.com/diljeet1994/Python_Tutorials/master/Projects/Advanced%20ETL/crypto-markets.csv)

我在这里采用了不同类型的数据，因为在实际项目中，有可能基于不同类型的数据及其来源创建多个转换。

> **配置**

为了处理它，我们将创建一个 JSON 配置文件，其中我们将提到所有这些数据源。我们将在 JSON 文件中创建“API”和“CSV”作为不同的键，并列出这两个类别下的数据源。这是一个 JSON 文件。

现在，如果将来我们有另一个数据源，假设是 MongoDB，我们可以很容易地在 JSON 文件中添加它的属性，看看下面的代码:

> **提取**

既然我们的数据源已经设置好，并且我们已经有了一个配置文件，我们可以从 ETL 管道的提取部分的编码开始。最好在 python 中创建一个类，它将处理不同的数据源用于提取目的。此外，通过编写一个类，我们遵循 OOP 的编程方法，并保持我们的代码**模块化或松散耦合**。因为我们只使用 API 和 CSV 文件作为数据源，所以我们将创建两个通用函数，分别处理 API 数据和 CSV 数据。看看下面的代码:

我们之前也讨论过**可伸缩性**。如果您再看一下上面的代码，您会发现我们可以添加更多的通用方法(如 MongoDB 或 Oracle 数据库)来处理它们以进行数据提取。因为方法是通用的，可以很容易地添加更多的通用方法，所以我们可以很容易地在以后的任何项目中重用这些代码。

> **加载**

让我们创建另一个模块进行加载。我将创建一个类来处理 MongoDB 数据库，以便在我们的 ETL 管道中加载数据。代码将再次基于模块化和可伸缩性的概念。看看下面的代码:

在这里，您可以看到 MongoDb 连接属性正在 MongoDB 类初始化器(这个函数 __init__())中设置，记住我们可以使用多个 MongoDB 实例。因此，每当我们创建这个类的对象时，我们将使用特定的 MongoDB 实例属性对其进行初始化，以便用于读取或写入目的。

上面的代码中添加了插入和读取 MongoDb 的方法，同样，您也可以添加更新和删除的通用方法。自己尝试一下，然后摆弄一下代码。

> **转换**

我们可以从编码转换类开始。因为转换是基于业务需求的，所以在这里保持模块性是非常困难的，但是，我们将通过再次使用 OOP 的概念使我们的类可伸缩。

到目前为止，我们必须处理 3 个转换，即污染数据、经济数据和加密货币数据。由于不同数据源的转换逻辑不同，所以我们将为每个转换创建不同的类方法。

为了简单起见，试着把重点放在类结构上，并理解设计它背后的观点。我并不是说这是唯一的编码方式，但肯定是一种方式，如果你有更好的建议，请在评论中告诉我。

此外，如果您对代码逻辑或数据源的理解有任何疑问，请在评论部分提出。

好的，首先看看下面的代码，然后我会试着解释它。

代码段看起来很大，但是不用担心，解释更简单。让我们从初始化器开始，一旦我们用 dataSource 和 dataSet 作为 object 的参数创建了 Transformation 类的对象，它的初始化器将被这些参数调用，在初始化器内部，Extract class 对象将基于传递的参数创建，以便我们获取所需的数据。同样，基于我们创建转换类对象时传递的参数(数据源和数据集),将调用提取类方法，然后调用转换类方法，所以这是基于我们传递给转换类对象的参数自动进行的。

现在，转换类的 3 个方法如下:

*   apiEconomy():它获取经济数据并计算每年的 GDP 增长。
*   apiPollution():这个函数只是读取嵌套的字典数据，取出相关数据并将其转储到 MongoDB 中。
*   csvCryptomarkets():这个函数从一个 CSV 文件中读取数据，并将加密货币的价格转换成英镑(GBP ),然后转储到另一个 CSV 文件中。

我们可以很容易地根据新的转换需求添加新的函数，并在配置文件和提取类中管理它的数据源。

此外，如果我们想要添加另一个资源来加载我们的数据，比如 Oracle 数据库，我们可以简单地为 Oracle 类创建一个新的模块，就像我们为 MongoDB 所做的那样。

> **自动化 ETL 管道**

唯一剩下的事情是，如何自动化这条管道，以便即使没有人工干预，它每天运行一次。

为此，我们可以创建另一个文件，让我们把它命名为 main.py，在这个文件中，我们将使用 Transformation class object，然后利用循环逐个运行它的所有方法。看看下面的代码片段。

由于转换类初始化器期望 dataSource 和 dataSet 作为参数，所以在我们上面的代码中，我们从 data_config.json 文件中读取数据源，并将数据源名称及其值传递给转换类，然后转换类初始化器将在接收到数据源和数据集作为参数后自行调用类方法，如上所述。

要每天运行这个 ETL 管道，如果您在 linux 服务器上，请设置一个 cron 作业。您也可以使用 Python 调度程序，但这是一个单独的主题，所以这里不做解释。

这里是 GitHub 的 url，可以获得整个项目的 jupyter 笔记本。[https://github . com/dil Jeet 1994/Python _ Tutorials/tree/master/Projects/Advanced % 20 ETL](https://github.com/diljeet1994/Python_Tutorials/tree/master/Projects/Advanced%20ETL)

希望你觉得这个博客有些用处。

玩得开心，不断学习，一直坚持编码。

谢了。