# 我们为适应性学习做好准备了吗？

> 原文：<https://medium.datadriveninvestor.com/how-ready-are-we-for-adaptive-learning-c90bd03f55c6?source=collection_archive---------22----------------------->

![](img/482fcd7f58fc9ba835986bdf3701c814.png)

Image credit: [Vecteezy](http://<a href="https://www.vecteezy.com">Design Credits: vecteezy.com</a>)

我正在解决一个“棘手的问题”——试图设计一个为适应性学习寻求专家意见的解决方案。这个话题并不新鲜。机器学习领域的自适应学习也不是什么新鲜事。使它成为“邪恶问题”的是，它在真实世界中的适用性和在目标受众中的采用。

自适应学习的全部主张是学习和改进，以使输出更可靠，讽刺的是，这正是使它在专家中不那么值得信任的相同过程。

想想看，‘我(一个专家)被期望告诉一台机器它是对的/错的，这样它就可以做我这辈子很长时间用我的大脑做的事情。’唷！那是一座难以攀登的山。在这篇文章中，我写到了对专家的同情。

为了找到一些解决方案，我花了很多时间阅读关于适应性学习挑战的学术论文和其他文章:

*   输出的可解释性——算法越复杂和精密，它们就越不可解释，但结果越准确。在专家采纳方面，这是最好的。或者赢得他们的信任。专家喜欢深入细节。如果他们理解不够，他们的大脑和长期的专业知识是他们所依赖的。
*   我还观察到，专家们迄今为止使用的系统并不是为了捕捉关键的“使用”数据而设计的，而这些数据在今天的背景下可以成为适应性学习的输入。
*   最重要的是。到处都在谈论的一个一致的障碍是缺乏信任。

作为我思考和研究过程的一部分，我试图寻找相邻的领域来学习。其中一个我拿来比较的是，自动驾驶汽车。虽然它已经走过了漫长的道路，但由于各方面的原因，它仍然没有被采用。其中一个重要原因是缺乏信任。

截至今天，一些高端汽车的新型号已经有数以吨计的传感器，可以测量自己和前面汽车之间的距离；需要时休息；评估变道、自行停车等的安全时间。然而，司机仍然在方向盘后面，可以在任何时候收回控制权。

> 当利害攸关时，一个人仍然信任另一个人。

毕竟我们生活中还有纸和签名。没有数字签名或在线系统让纸张消失。

根据我的研究性学习、观察和直觉，我觉得自适应学习在关键决策环境中的应用仍处于非常早期的阶段——尤其是将它放在专家的手中进行工作。

现在可能是创建一些蓝图，为其奠定基础，并在测试场景中运行的好时机——可能就像汽车行业的碰撞测试一样。在模拟装置/数字孪生机上测试“故障概率”预测的准确性，以便反过来学习和改进。

说什么？