# AI 是不是数据越大越好？

> 原文：<https://medium.datadriveninvestor.com/is-ai-better-with-bigger-data-5aacc506d03b?source=collection_archive---------15----------------------->

![](img/94306ee1f21f5408b61330d129195c2c.png)

“With huge data, we will make AI great again!” — *HAL 9000*

数字化和数字化转型的加速推动了数据的爆炸式增长，对于组织来说，保持和利用这种新的“自然资源”正变得越来越具有挑战性。幸运的是，人工智能(AI)的日益普及正在帮助专业人士利用大数据的潜力来改善他们的工作和决策质量。有了人工智能工具，大量数据的淘洗已经在企业中认真开始——希望找到真知灼见，以提供更好的业务成果。

然而，更大的数据实际上是在推动人工智能提供更好的建议或决策吗？视觉识别神经网络是在一组不同的面部图像上进行训练，还是大部分数据集主要来自肤色较浅的男性人群？借款人是否处于不利地位，因为金融机构根据他们经常购物的商店的其他客户的还款历史对信用风险进行评分，即受到协会的处罚？或者更糟糕的是，执法机构是否在没有相关背景的情况下，通过孤立地分析社交媒体和移动数据的丰富线索，使用人工智能系统来描述公民？

如果由于次优采样或机器学习模型的不适当训练，数据集对某些人口统计数据(例如，性别、种族、年龄、社会/经济地位)的代表性不足，则具有更多属性的更多数据可能会导致偏差。来自更多来源的更多数据也意味着，在整个人工智能开发过程中，它更容易受到操纵、攻击和妥协。因此，从训练数据和处理到测试和部署，数据驱动的决策过程的每一步都必须通过显示哪些因素在一个方向上相对于另一个方向对决策进行加权、对建议的信心以及支持这种信心的因素来解释。

当使用大量大数据训练人工智能时，偏见的存在通常是历史因素或源材料缺乏多样性的结果。这就是为什么筛选数据并最终指导决策的算法很容易受到内在偏见的影响，即使数据公平与否。人工智能只有在它接受训练或获得数据时才是公正的。如果没有源数据的充分平衡和训练的严格性，人工智能模型可能会简单地重复这种偏见，同时给它一种计算机生成的中立性的外表。

因此，采用人工智能的组织引入检查器来检测训练数据和模型中的偏差是至关重要的；在人工智能管道的各个阶段查明偏差来源并推荐缓解策略的工具；和端到端血统管理来跟踪 AI 系统的完整开发。在急于利用这种大规模数据爆炸的潜力和人工智能的相应应用时，我们不能忽视个人、企业和社区的基本权利和期望。

在[https://www . IBM . com/blogs/Watson/2018/09/trust-transparency-AI/](https://www.ibm.com/blogs/watson/2018/09/trust-transparency-ai/)了解更多关于人工智能中信任和透明的信息。